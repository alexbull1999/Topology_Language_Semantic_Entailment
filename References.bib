@misc{bowman2015,
    author = {Samuel R. Bowman and Gabor Angeli and Christopher Potts and Christopher D. Manning}, 
    title = {A large annotated corpus for learning natural language inference},
    year = {2015},
    note = {arXiv:1508.05326 [cs.CL]. Available at: \url{https://arxiv.org/abs/1508.05326}}
}

@inbook{dagan2005,
    author = {Dagan, I. and Glickman, O. and Magnini, B.},
    title = {The PASCAL Recognising Textual Entailment Challenge. In: Machine Learning Challenges. Evaluating Predictive Uncertainty, Visual Object Classification, and Recognising Textual Entailment},
    publisher = {Springer, Berlin, Heidelberg},
    year = {2005},
    note = {\url{https://doi.org/10.1007/11736790_9}}
}

@article{PARAMASIVAM20229644,
title = {A survey on textual entailment based question answering},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {34},
number = {10, Part B},
pages = {9644-9653},
year = {2022},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2021.11.017},
url = {https://www.sciencedirect.com/science/article/pii/S1319157821003311},
author = {Aarthi Paramasivam and S. Jaya Nirmala},
keywords = {Natural Language Processing, Question Answering, Textual Entailment},
abstract = {Question answering, an information retrieval system that seeks knowledge, is one of the classic applications in Natural Language Processing. A question answering system comprises numerous sets of subtasks. Some of the subtasks are Passage Retrieval, Answer Ranking, Question Similarity, Question Generation, Question Classification, Answer Selection, and Answer Validation. Numerous approaches have been experimented on in the question answering system to achieve accurate results. One such approach for the question answering system is Textual Entailment. Textual Entailment is a framework that captures significant semantic inference. Textual Entailment of two text fragments can be defined as the task of deciding whether the meaning of one text fragment can be inferred from another text fragment. This survey discusses how and why Textual Entailment is applied to various subtasks in question answering.}
}

@inproceedings{merrill-etal-2022-entailment,
    title = "Entailment Semantics Can Be Extracted from an Ideal Language Model",
    author = "Merrill, William  and
      Warstadt, Alex  and
      Linzen, Tal",
    editor = "Fokkens, Antske  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 26th Conference on Computational Natural Language Learning (CoNLL)",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates (Hybrid)",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.conll-1.13/",
    doi = "10.18653/v1/2022.conll-1.13",
    pages = "176--193",
    abstract = "Language models are often trained on text alone, without additional grounding. There is debate as to how much of natural language semantics can be inferred from such a procedure. We prove that entailment judgments between sentences can be extracted from an ideal language model that has perfectly learned its target distribution, assuming the training sentences are generated by Gricean agents, i.e., agents who follow fundamental principles of communication from the linguistic theory of pragmatics. We also show entailment judgments can be decoded from the predictions of a language model trained on such Gricean data. Our results reveal a pathway for understanding the semantic information encoded in unlabeled linguistic data and a potential framework for extracting semantics from language models."
}

@inproceedings{bender-koller-2020-climbing,
    title = "Climbing towards {NLU}: {On} Meaning, Form, and Understanding in the Age of Data",
    author = "Bender, Emily M.  and
      Koller, Alexander",
    editor = "Jurafsky, Dan  and
      Chai, Joyce  and
      Schluter, Natalie  and
      Tetreault, Joel",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.463/",
    doi = "10.18653/v1/2020.acl-main.463",
    pages = "5185--5198",
    abstract = "The success of the large neural language models on many NLP tasks is exciting. However, we find that these successes sometimes lead to hype in which these models are being described as {\textquotedblleft}understanding{\textquotedblright} language or capturing {\textquotedblleft}meaning{\textquotedblright}. In this position paper, we argue that a system trained only on form has a priori no way to learn meaning. In keeping with the ACL 2020 theme of {\textquotedblleft}Taking Stock of Where We{'}ve Been and Where We{'}re Going{\textquotedblright}, we argue that a clear understanding of the distinction between form and meaning will help guide the field towards better science around natural language understanding."
}

@article{hogarthFT,
    author = {Ian Hogarth},
    title = {We must slow down the race to god-like {AI}},
    journal = {Financial Times, 12/04/2023},
    year = {}
}

@book{brecht,
    author = {Bertolt Brecht},
    title = {Bertolt Brecht Werke: Schriften 3. Vol. 23.},
    publisher = {Berlin: Aufbau-Verlag},
    year = {1993},
    note = {Translation by Alex Bull}
}

@book{derrida1,
    author = {Jacques Derrida},
    title = {De la Grammatologie},
    publisher = {Les Éditions de Minuit},
    year = {1967}
}

@book{derrida2,
    author = {Jacques Derrida},
    title = {L'Écriture et la Différence},
    publisher = {Éditions du Seuil},
    year = {1967}
}

@book{derrida3,
    author = {Jacques Derrida},
    title = {Le monolinguisme de l'autre: ou la prothèse d'origine},
    publisher = {Éditions Galilée},
    year = {1996}
}

@article{forbesChatGPT,
    author = {Martine Paris},
    title = {ChatGPT Hits 1 Billion Users? ‘{Doubled} In Just Weeks’ Says {OpenAI} {CEO}},
    journal = {Forbes},
    year = {12/04/2025},
    note = {https://www.forbes.com/sites/martineparis/2025/04/12/chatgpt-hits-1-billion-users-openai-ceo-says-doubled-in-weeks/. Accessed: 01/06/2025}
}

@misc{fitz2024hiddenholestopologicalaspects,
      title={Hidden Holes: topological aspects of language models}, 
      author={Stephen Fitz and Peter Romero and Jiyan Jonas Schneider},
      year={2024},
      eprint={2406.05798},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.05798}, 
}


@InProceedings{fitz22a,
  title = 	 {The Shape of Words - topological structure in natural language data},
  author =       {Fitz, Stephen},
  booktitle = 	 {Proceedings of Topological, Algebraic, and Geometric Learning Workshops 2022},
  pages = 	 {116--123},
  year = 	 {2022},
  editor = 	 {Cloninger, Alexander and Doster, Timothy and Emerson, Tegan and Kaul, Manohar and Ktena, Ira and Kvinge, Henry and Miolane, Nina and Rieck, Bastian and Tymochko, Sarah and Wolf, Guy},
  volume = 	 {196},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {25 Feb--22 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v196/fitz22a/fitz22a.pdf},
  url = 	 {https://proceedings.mlr.press/v196/fitz22a.html},
  abstract = 	 {This paper presents a novel method, based on the ideas from algebraic topology, for the analysis of raw natural language text. The paper introduces the notion of a word manifold - a simplicial complex, whose topology encodes grammatical structure expressed by the corpus. Results of experiments with a variety of natural and synthetic languages are presented, showing that the homotopy type of the word manifold is influenced by linguistic structure. The analysis includes a new approach to the Voynich Manuscript - an unsolved puzzle in corpus linguistics. In contrast to existing topological data analysis approaches, we do not rely on the apparatus of persistent homology. Instead, we develop a method of generating topological structure directly from strings of words.}
}


@article{leibnizianAnalysis,
	author = {Jennings, R. E. and Chen, Y. and Sahasrabudhe, J.},
	date = {2011/04/01},
	date-added = {2025-06-02 11:56:16 +0100},
	date-modified = {2025-06-02 11:56:16 +0100},
	doi = {10.1007/s11787-011-0027-4},
	id = {Jennings2011},
	isbn = {1661-8300},
	journal = {Logica Universalis},
	number = {1},
	pages = {101--113},
	title = {On a New Idiom in the Study of Entailment},
	url = {https://doi.org/10.1007/s11787-011-0027-4},
	volume = {5},
	year = {2011},
	bdsk-url-1 = {https://doi.org/10.1007/s11787-011-0027-4}
}


@misc{fSadri,
    author = {Fariba Sadri},
    title = {Logic and Maths for Computing Lecture Notes},
    year = {2025},
    note = {Imperial MSc Computing Module}
}

@conference{Cederquist,
    title = "Entailment relations and distributive lattices",
    abstract = "To any entailment relation [Sco74] we associate a distributive lattice. We use this to give a construction of the product of lattices over an arbitrary index set, of the Vietoris construction, of the embedding of a distributive lattice in a boolean algebra, and to give a logical description of some spaces associated to mathematical structures.",
    keywords = "IR-56168, EWI-985",
    author = "Sam Buss and J.G. Cederquist and Thierry Coquand and Petr Hajek and Pavel Pudlak",
    note = "Imported from DIES; Logic Colloquium 1998 ; Conference date: 09-08-1998 Through 15-08-1998",
    year = "2000",
    month = jan,
    language = "Undefined",
    pages = "110--123"
}

@article{Evans2018,
    author = {Evans, Richard and Saxton, David and Amos, David and Kohli, Pushmeet and Grefenstette, Edward},
    year = {2018},
    month = {02},
    pages = {},
    title = {Can Neural Networks Understand Logical Entailment?},
    doi = {10.48550/arXiv.1802.08535}
}

@inproceedings{poliak-2020-survey,
    title = "A survey on Recognizing Textual Entailment as an {NLP} Evaluation",
    author = "Poliak, Adam",
    editor = "Eger, Steffen  and
      Gao, Yang  and
      Peyrard, Maxime  and
      Zhao, Wei  and
      Hovy, Eduard",
    booktitle = "Proceedings of the First Workshop on Evaluation and Comparison of NLP Systems",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.eval4nlp-1.10/",
    doi = "10.18653/v1/2020.eval4nlp-1.10",
    pages = "92--109",
    abstract = "Recognizing Textual Entailment (RTE) was proposed as a unified evaluation framework to compare semantic understanding of different NLP systems. In this survey paper, we provide an overview of different approaches for evaluating and understanding the reasoning capabilities of NLP systems. We then focus our discussion on RTE by highlighting prominent RTE datasets as well as advances in RTE dataset that focus on specific linguistic phenomena that can be used to evaluate NLP systems on a fine-grained level. We conclude by arguing that when evaluating NLP systems, the community should utilize newly introduced RTE datasets that focus on specific linguistic phenomena."
}

@InCollection{sep-montague-semantics,
	author       =	{Janssen, Theo M. V. and Zimmermann, Thomas Ede},
	title        =	{{Montague Semantics}},
	booktitle    =	{The {Stanford} Encyclopedia of Philosophy},
	editor       =	{Edward N. Zalta and Uri Nodelman},
	howpublished =	{\url{https://plato.stanford.edu/archives/spr2025/entries/montague-semantics/}},
	year         =	{2025},
	edition      =	{{S}pring 2025},
	publisher    =	{Metaphysics Research Lab, Stanford University}
}

@article{estival1997,
author = {Estival, Dominique},
year = {1997},
month = {12},
pages = {375-379},
title = {Karen Sparck Jones and Julia R. Galliers, Evaluating Natural Language Processing Systems: An Analysis and Review. Lecture Notes in Artificial Intelligence 1083},
volume = {12},
journal = {Machine Translation},
doi = {10.1023/A:1007918307730}
}

@inproceedings{white-etal-2017-inference,
    title = "Inference is Everything: Recasting Semantic Resources into a Unified Evaluation Framework",
    author = "White, Aaron Steven  and
      Rastogi, Pushpendre  and
      Duh, Kevin  and
      Van Durme, Benjamin",
    editor = "Kondrak, Greg  and
      Watanabe, Taro",
    booktitle = "Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = nov,
    year = "2017",
    address = "Taipei, Taiwan",
    publisher = "Asian Federation of Natural Language Processing",
    url = "https://aclanthology.org/I17-1100/",
    pages = "996--1005",
    abstract = "We propose to unify a variety of existing semantic classification tasks, such as semantic role labeling, anaphora resolution, and paraphrase detection, under the heading of Recognizing Textual Entailment (RTE). We present a general strategy to automatically generate one or more sentential hypotheses based on an input sentence and pre-existing manual semantic annotations. The resulting suite of datasets enables us to probe a statistical RTE model{'}s performance on different aspects of semantics. We demonstrate the value of this approach by investigating the behavior of a popular neural network RTE model."
}

@article{CooperFracas,
author = {Cooper, Robin and Milward, David and Pinkal, Manfred and Poesio, Massimo and Pulman, Steve and D, Deliverable},
year = {1996},
month = {02},
pages = {},
title = {A Strategy for Building a Framework for Computational Semantics (The Way Forward)}
}

@inproceedings{dzikovska-etal-2013-semeval,
    title = "{S}em{E}val-2013 Task 7: The Joint Student Response Analysis and 8th Recognizing Textual Entailment Challenge",
    author = "Dzikovska, Myroslava  and
      Nielsen, Rodney  and
      Brew, Chris  and
      Leacock, Claudia  and
      Giampiccolo, Danilo  and
      Bentivogli, Luisa  and
      Clark, Peter  and
      Dagan, Ido  and
      Dang, Hoa Trang",
    editor = "Manandhar, Suresh  and
      Yuret, Deniz",
    booktitle = "Second Joint Conference on Lexical and Computational Semantics (*{SEM}), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation ({S}em{E}val 2013)",
    month = jun,
    year = "2013",
    address = "Atlanta, Georgia, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/S13-2045/",
    pages = "263--274"
}

@inproceedings{marelli-etal-2014-sick,
    title = "A {SICK} cure for the evaluation of compositional distributional semantic models",
    author = "Marelli, Marco  and
      Menini, Stefano  and
      Baroni, Marco  and
      Bentivogli, Luisa  and
      Bernardi, Raffaella  and
      Zamparelli, Roberto",
    editor = "Calzolari, Nicoletta  and
      Choukri, Khalid  and
      Declerck, Thierry  and
      Loftsson, Hrafn  and
      Maegaard, Bente  and
      Mariani, Joseph  and
      Moreno, Asuncion  and
      Odijk, Jan  and
      Piperidis, Stelios",
    booktitle = "Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14)",
    month = may,
    year = "2014",
    address = "Reykjavik, Iceland",
    publisher = "European Language Resources Association (ELRA)",
    url = "https://aclanthology.org/L14-1314/",
    pages = "216--223",
    abstract = "Shared and internationally recognized benchmarks are fundamental for the development of any computational system. We aim to help the research community working on compositional distributional semantic models (CDSMs) by providing SICK (Sentences Involving Compositional Knowldedge), a large size English benchmark tailored for them. SICK consists of about 10,000 English sentence pairs that include many examples of the lexical, syntactic and semantic phenomena that CDSMs are expected to account for, but do not require dealing with other aspects of existing sentential data sets (idiomatic multiword expressions, named entities, telegraphic language) that are not within the scope of CDSMs. By means of crowdsourcing techniques, each pair was annotated for two crucial semantic tasks: relatedness in meaning (with a 5-point rating scale as gold score) and entailment relation between the two elements (with three possible gold labels: entailment, contradiction, and neutral). The SICK data set was used in SemEval-2014 Task 1, and it freely available for research purposes."
}

@inproceedings{williams-etal-2018-broad,
    title = "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference",
    author = "Williams, Adina  and
      Nangia, Nikita  and
      Bowman, Samuel",
    editor = "Walker, Marilyn  and
      Ji, Heng  and
      Stent, Amanda",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N18-1101/",
    doi = "10.18653/v1/N18-1101",
    pages = "1112--1122",
    abstract = "This paper introduces the Multi-Genre Natural Language Inference (MultiNLI) corpus, a dataset designed for use in the development and evaluation of machine learning models for sentence understanding. At 433k examples, this resource is one of the largest corpora available for natural language inference (a.k.a. recognizing textual entailment), improving upon available resources in both its coverage and difficulty. MultiNLI accomplishes this by offering data from ten distinct genres of written and spoken English, making it possible to evaluate systems on nearly the full complexity of the language, while supplying an explicit setting for evaluating cross-genre domain adaptation. In addition, an evaluation using existing machine learning models designed for the Stanford NLI corpus shows that it represents a substantially more difficult task than does that corpus, despite the two showing similar levels of inter-annotator agreement."
}

@article{Khot_Sabharwal_Clark_2018, title={SciTaiL: A Textual Entailment Dataset from Science Question Answering}, volume={32}, url={https://ojs.aaai.org/index.php/AAAI/article/view/12022}, DOI={10.1609/aaai.v32i1.12022}, number={1}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Khot, Tushar and Sabharwal, Ashish and Clark, Peter}, year={2018}, month={Apr.} }

@InProceedings{shajalal,
author="Shajalal, Md
and Atabuzzaman, Md.
and Baby, Maksuda Bilkis
and Karim, Md. Rezaul
and Boden, Alexander",
editor="M, Anand Kumar
and Chakravarthi, Bharathi Raja
and B, Bharathi
and O'Riordan, Colm
and Murthy, Hema
and Durairaj, Thenmozhi
and Mandl, Thomas",
title="Textual Entailment Recognition with Semantic Features from Empirical Text Representation",
booktitle="Speech and Language Technologies for Low-Resource Languages ",
year="2023",
publisher="Springer International Publishing",
address="Cham",
pages="183--195",
abstract="Textual entailment recognition is one of the basic natural language understanding (NLU) tasks. Understanding the meaning of sentences is a prerequisite before applying any natural language processing (NLP) techniques to automatically recognize the textual entailment. A text entails a hypothesis if and only if the true meaning and intent of the hypothesis follows the text. Classical approaches generally utilize the feature value of each word from word embedding to represent the sentences. In this paper, we propose a new framework to identify the textual entailment relationship between text and hypothesis, thereby introducing a new semantic feature focusing on empirical threshold-based semantic text representation. We employ an element-wise Manhattan distance vector-based feature that can identify the semantic entailment relationship between the text-hypothesis pair. We carried out several experiments on a benchmark entailment classification (SICK-RTE) dataset. We train several machine learning (ML) algorithms applying both semantic and lexical features to classify the text-hypothesis pair as entailment, neutral, or contradiction. Our empirical sentence representation technique enriches the semantic information of the texts and hypotheses found to be more efficient than the classical ones. In the end, our approach significantly outperforms known methods in understanding the meaning of the sentences for the textual entailment classification task.",
isbn="978-3-031-33231-9"
}

@phdthesis{pavlick2017,
    author = {Ellie Pavlick},
    title = {Compositional Lexical Entailment for Natural Language Inference},
    school = {University of Pennsylvania},
    year = {2017}
}

@misc{sanwal2024evaluatinglargelanguagemodels,
      title={Evaluating Large Language Models Using Contrast Sets: An Experimental Approach}, 
      author={Manish Sanwal},
      year={2024},
      eprint={2404.01569},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.01569}, 
}

@misc{xie2019visualentailmentnoveltask,
      title={Visual Entailment: A Novel Task for Fine-Grained Image Understanding}, 
      author={Ning Xie and Farley Lai and Derek Doran and Asim Kadav},
      year={2019},
      eprint={1901.06706},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1901.06706}, 
}

@inproceedings{savle-etal-2019-topological,
    title = "Topological Data Analysis for Discourse Semantics?",
    author = "Savle, Ketki  and
      Zadrozny, Wlodek  and
      Lee, Minwoo",
    editor = "Dobnik, Simon  and
      Chatzikyriakidis, Stergios  and
      Demberg, Vera  and
      Abu Kwaik, Kathrein  and
      Maraev, Vladislav",
    booktitle = "Proceedings of the 13th International Conference on Computational Semantics - Student Papers",
    month = may,
    year = "2019",
    address = "Gothenburg, Sweden",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W19-0605/",
    doi = "10.18653/v1/W19-0605",
    pages = "34--43",
    abstract = "In this paper we present new results on applying topological data analysis to discourse structures. We show that topological information, extracted from the relationships between sentences can be used in inference, namely it can be applied to the very difficult legal entailment given in the COLIEE 2018 data set. Previous results of Doshi and Zadrozny (2018) and Gholizadeh et al. (2018) show that topological features are useful for classification. The applications of computational topology to entailment are novel in our view provide a new set of tools for discourse semantics: computational topology can perhaps provide a bridge between the brittleness of logic and the regression of neural networks. We discuss the advantages and disadvantages of using topological information, and some open problems such as explainability of the classifier decisions."
}

@misc{uchendu2024unveilingtopologicalstructurestext,
      title={Unveiling Topological Structures in Text: A Comprehensive Survey of Topological Data Analysis Applications in NLP}, 
      author={Adaku Uchendu and Thai Le},
      year={2024},
      eprint={2411.10298},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2411.10298}, 
}

@article{Huang:18,
author = {He-Liang Huang and Xi-Lin Wang and Peter P. Rohde and Yi-Han Luo and You-Wei Zhao and Chang Liu and Li Li and Nai-Le Liu and Chao-Yang Lu and Jian-Wei Pan},
journal = {Optica},
keywords = {Quantum optics; Quantum information and processing ; Image analysis; Machine learning; Nodal aberration theory; Photonic entanglement; Quantum computation; Signal processing},
number = {2},
pages = {193--198},
publisher = {Optica Publishing Group},
title = {Demonstration of topological data analysis on a quantum processor},
volume = {5},
month = {Feb},
year = {2018},
url = {https://opg.optica.org/optica/abstract.cfm?URI=optica-5-2-193},
doi = {10.1364/OPTICA.5.000193},
abstract = {Topological data analysis offers a robust way to extract useful information from noisy, unstructured data by identifying its underlying structure. Recently, an efficient quantum algorithm was proposed \[Nat. Commun.7, 10138 (2016)NCAOBW2041-172310.1038/ncomms10138\] for calculating Betti numbers of data points\&\#x2014;topological features that count the number of topological holes of various dimensions in a scatterplot. Here, we implement a proof-of-principle demonstration of this quantum algorithm by employing a six-photon quantum processor to successfully analyze the topological features of Betti numbers of a network including three data points, providing new insights into data analysis in the era of quantum computing.},
}

@inproceedings{singh2007,
booktitle = {Eurographics Symposium on Point-Based Graphics},
editor = {M. Botsch and R. Pajarola and B. Chen and M. Zwicker},
title = {{Topological Methods for the Analysis of High Dimensional Data Sets and 3D Object Recognition}},
author = {Singh, Gurjeet and Memoli, Facundo and Carlsson, Gunnar},
year = {2007},
publisher = {The Eurographics Association},
ISSN = {1811-7813},
ISBN = {978-3-905673-51-7},
DOI = {/10.2312/SPBG/SPBG07/091-100}
}


@article{port2018,
	author = {Port, Alexander and Gheorghita, Iulia and Guth, Daniel and Clark, John M. and Liang, Crystal and Dasu, Shival and Marcolli, Matilde},
	journal = {Mathematics in Computer Science},
	number = {1},
	pages = {33--50},
	title = {Persistent Topology of Syntax},
	volume = {12},
	year = {2018}}

@article{port2022,
author = {Port, Alex and Karidi, Taelin and Marcolli, Matilde},
year = {2022},
month = {01},
pages = {},
title = {Topological Analysis of Syntactic Structures},
volume = {16},
journal = {Mathematics in Computer Science},
doi = {10.1007/s11786-021-00520-5}
}


@inproceedings{zhu2013,
author = {Zhu, Xiaojin},
year = {2013},
month = {08},
pages = {1953-1959},
title = {Persistent homology: An introduction and a new text representation for natural language processing},
journal = {IJCAI International Joint Conference on Artificial Intelligence}
}


@INPROCEEDINGS{tymochko2021,
  author={Tymochko, Sarah and Chaput, Julien and Doster, Timothy and Purvine, Emilie and Warley, Jackson and Emerson, Tegan},
  booktitle={2021 20th IEEE International Conference on Machine Learning and Applications (ICMLA)}, 
  title={Con Connections: Detecting Fraud from Abstracts using Topological Data Analysis}, 
  year={2021},
  volume={},
  number={},
  pages={403-408},
  keywords={Data analysis;Conferences;Time series analysis;Machine learning;Linguistics;Feature extraction;Natural language processing;topological data analysis;persistent homology;persistence images;fraud detection;natural language processing},
  doi={10.1109/ICMLA52953.2021.00069}}


@misc{uchendu2024topformertopologyawareauthorshipattribution,
      title={TOPFORMER: Topology-Aware Authorship Attribution of Deepfake Texts with Diverse Writing Styles}, 
      author={Adaku Uchendu and Thai Le and Dongwon Lee},
      year={2024},
      eprint={2309.12934},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2309.12934}, 
}

@misc{tulchinskii2023intrinsicdimensionestimationrobust,
      title={Intrinsic Dimension Estimation for Robust Detection of AI-Generated Texts}, 
      author={Eduard Tulchinskii and Kristian Kuznetsov and Laida Kushnareva and Daniil Cherniavskii and Serguei Barannikov and Irina Piontkovskaya and Sergey Nikolenko and Evgeny Burnaev},
      year={2023},
      eprint={2306.04723},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2306.04723}, 
}

@misc{kushnareva2024aigeneratedtextboundarydetection,
      title={AI-generated text boundary detection with RoFT}, 
      author={Laida Kushnareva and Tatiana Gaintseva and German Magai and Serguei Barannikov and Dmitry Abulkhanov and Kristian Kuznetsov and Eduard Tulchinskii and Irina Piontkovskaya and Sergey Nikolenko},
      year={2024},
      eprint={2311.08349},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2311.08349}, 
}

@inproceedings{cherniavskii-etal-2022-acceptability,
    title = "Acceptability Judgements via Examining the Topology of Attention Maps",
    author = "Cherniavskii, Daniil  and
      Tulchinskii, Eduard  and
      Mikhailov, Vladislav  and
      Proskurina, Irina  and
      Kushnareva, Laida  and
      Artemova, Ekaterina  and
      Barannikov, Serguei  and
      Piontkovskaya, Irina  and
      Piontkovski, Dmitri  and
      Burnaev, Evgeny",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2022",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-emnlp.7/",
    doi = "10.18653/v1/2022.findings-emnlp.7",
    pages = "88--107",
    abstract = "The role of the attention mechanism in encoding linguistic knowledge has received special interest in NLP. However, the ability of the attention heads to judge the grammatical acceptability of a sentence has been underexplored. This paper approaches the paradigm of acceptability judgments with topological data analysis (TDA), showing that the geometric properties of the attention graph can be efficiently exploited for two standard practices in linguistics: binary judgments and linguistic minimal pairs. Topological features enhance the BERT-based acceptability classifier scores by 8{\%}-24{\%} on CoLA in three languages (English, Italian, and Swedish). By revealing the topological discrepancy between attention maps of minimal pairs, we achieve the human-level performance on the BLiMP benchmark, outperforming nine statistical and Transformer LM baselines. At the same time, TDA provides the foundation for analyzing the linguistic functions of attention heads and interpreting the correspondence between the graph features and grammatical phenomena. We publicly release the code and other materials used in the experiments."
}

@misc{elyasi2019introductionnewtextclassification,
      title={An Introduction to a New Text Classification and Visualization for Natural Language Processing Using Topological Data Analysis}, 
      author={Naiereh Elyasi and Mehdi Hosseini Moghadam},
      year={2019},
      eprint={1906.01726},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1906.01726}, 
}

@inbook{doshi2018,
author = {Doshi, Pratik and Zadrozny, Wlodek},
year = {2018},
month = {01},
pages = {117-128},
title = {Movie Genre Detection Using Topological Data Analysis: 6th International Conference, SLSP 2018, Mons, Belgium, October 15–16, 2018, Proceedings},
isbn = {978-3-030-00809-3},
doi = {10.1007/978-3-030-00810-9_11}
}

@article{CHIANG2007256,
title = {Discover the semantic topology in high-dimensional data},
journal = {Expert Systems with Applications},
volume = {33},
number = {1},
pages = {256-262},
year = {2007},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2006.05.033},
url = {https://www.sciencedirect.com/science/article/pii/S0957417406001813},
author = {I-Jen Chiang},
keywords = {Document clustering, Association rules, Hierarchical clustering, Simplicial complex},
abstract = {Discovering the homogeneous concept groups in the high-dimensional data sets and clustering them accordingly are contemporary challenge. Conventional clustering techniques often based on Euclidean metric. However, the metric is ad hoc not intrinsic to the semantic of the documents. In this paper, we are proposing a novel approach, in which the semantic space of high-dimensional data is structured as a simplicial complex of Euclidean space (a hypergraph but with different focus). Such a simplicial structure intrinsically captures the semantic of the data; for example, the coherent topics of documents will appear in the same connected component. Finally, we cluster the data by the structure of concepts, which is organized by such a geometry.}
}


@inproceedings{karlgren2014,
author = {Karlgren, Jussi and Bohman, Martin and Ekgren, Ariel and Isheden, Gabriel and Kullmann, Emelie and Nilsson, David},
title = {Semantic Topology},
year = {2014},
isbn = {9781450325981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2661829.2662028},
doi = {10.1145/2661829.2662028},
abstract = {Semantic spaces, a useful learning framework for lexical resources, are typically treated as black boxes and applied using geometric and linear algebraic processing tools. We have found that topological methods are useful for exploring the makeup of a semantic space.},
booktitle = {Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management},
pages = {1939–1942},
numpages = {4},
keywords = {computational topology, distributional semantics, semantic topology},
location = {Shanghai, China},
series = {CIKM '14}
}

@misc{sun2023topologicalinterpretationsgpt3,
      title={Topological Interpretations of GPT-3}, 
      author={Tianyi Sun and Bradley Nelson},
      year={2023},
      eprint={2308.03565},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2308.03565}, 
}

@inproceedings{jakubowski-etal-2020-topology,
    title = "Topology of Word Embeddings: Singularities Reflect Polysemy",
    author = "Jakubowski, Alexander  and
      Gasic, Milica  and
      Zibrowius, Marcus",
    editor = "Gurevych, Iryna  and
      Apidianaki, Marianna  and
      Faruqui, Manaal",
    booktitle = "Proceedings of the Ninth Joint Conference on Lexical and Computational Semantics",
    month = dec,
    year = "2020",
    address = "Barcelona, Spain (Online)",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.starsem-1.11/",
    pages = "103--113",
    abstract = "The manifold hypothesis suggests that word vectors live on a submanifold within their ambient vector space. We argue that we should, more accurately, expect them to live on a \textit{pinched} manifold: a singular quotient of a manifold obtained by identifying some of its points. The identified, singular points correspond to polysemous words, i.e. words with multiple meanings. Our point of view suggests that monosemous and polysemous words can be distinguished based on the topology of their neighbourhoods. We present two kinds of empirical evidence to support this point of view: (1) We introduce a topological measure of polysemy based on persistent homology that correlates well with the actual number of meanings of a word. (2) We propose a simple, topologically motivated solution to the SemEval-2010 task on \textit{Word Sense Induction {\&} Disambiguation} that produces competitive results."
}

@misc{temčinas2018localhomologywordembeddings,
      title={Local Homology of Word Embeddings}, 
      author={Tadas Temčinas},
      year={2018},
      eprint={1810.10136},
      archivePrefix={arXiv},
      primaryClass={math.AT},
      url={https://arxiv.org/abs/1810.10136}, 
}

@misc{ganea2018hyperbolicentailmentconeslearning,
      title={Hyperbolic Entailment Cones for Learning Hierarchical Embeddings}, 
      author={Octavian-Eugen Ganea and Gary Bécigneul and Thomas Hofmann},
      year={2018},
      eprint={1804.01882},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1804.01882}, 
}

@misc{dhall2020hierarchicalimageclassificationusing,
      title={Hierarchical Image Classification using Entailment Cone Embeddings}, 
      author={Ankit Dhall and Anastasia Makarova and Octavian Ganea and Dario Pavllo and Michael Greeff and Andreas Krause},
      year={2020},
      eprint={2004.03459},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2004.03459}, 
}

@misc{vendrov2016orderembeddingsimageslanguage,
      title={Order-Embeddings of Images and Language}, 
      author={Ivan Vendrov and Ryan Kiros and Sanja Fidler and Raquel Urtasun},
      year={2016},
      eprint={1511.06361},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1511.06361}, 
}