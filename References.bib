@misc{bowman2015,
    author = {Samuel R. Bowman and Gabor Angeli and Christopher Potts and Christopher D. Manning}, 
    title = {A large annotated corpus for learning natural language inference},
    year = {2015},
    note = {arXiv:1508.05326 [cs.CL]. Available at: \url{https://arxiv.org/abs/1508.05326}}
}

@inbook{dagan2005,
    author = {Dagan, I. and Glickman, O. and Magnini, B.},
    title = {The PASCAL Recognising Textual Entailment Challenge. In: Machine Learning Challenges. Evaluating Predictive Uncertainty, Visual Object Classification, and Recognising Textual Entailment},
    publisher = {Springer, Berlin, Heidelberg},
    year = {2005},
    note = {\url{https://doi.org/10.1007/11736790_9}}
}

@article{PARAMASIVAM20229644,
title = {A survey on textual entailment based question answering},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {34},
number = {10, Part B},
pages = {9644-9653},
year = {2022},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2021.11.017},
url = {https://www.sciencedirect.com/science/article/pii/S1319157821003311},
author = {Aarthi Paramasivam and S. Jaya Nirmala},
keywords = {Natural Language Processing, Question Answering, Textual Entailment},
abstract = {Question answering, an information retrieval system that seeks knowledge, is one of the classic applications in Natural Language Processing. A question answering system comprises numerous sets of subtasks. Some of the subtasks are Passage Retrieval, Answer Ranking, Question Similarity, Question Generation, Question Classification, Answer Selection, and Answer Validation. Numerous approaches have been experimented on in the question answering system to achieve accurate results. One such approach for the question answering system is Textual Entailment. Textual Entailment is a framework that captures significant semantic inference. Textual Entailment of two text fragments can be defined as the task of deciding whether the meaning of one text fragment can be inferred from another text fragment. This survey discusses how and why Textual Entailment is applied to various subtasks in question answering.}
}

@inproceedings{merrill-etal-2022-entailment,
    title = "Entailment Semantics Can Be Extracted from an Ideal Language Model",
    author = "Merrill, William  and
      Warstadt, Alex  and
      Linzen, Tal",
    editor = "Fokkens, Antske  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 26th Conference on Computational Natural Language Learning (CoNLL)",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates (Hybrid)",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.conll-1.13/",
    doi = "10.18653/v1/2022.conll-1.13",
    pages = "176--193",
    abstract = "Language models are often trained on text alone, without additional grounding. There is debate as to how much of natural language semantics can be inferred from such a procedure. We prove that entailment judgments between sentences can be extracted from an ideal language model that has perfectly learned its target distribution, assuming the training sentences are generated by Gricean agents, i.e., agents who follow fundamental principles of communication from the linguistic theory of pragmatics. We also show entailment judgments can be decoded from the predictions of a language model trained on such Gricean data. Our results reveal a pathway for understanding the semantic information encoded in unlabeled linguistic data and a potential framework for extracting semantics from language models."
}

@inproceedings{bender-koller-2020-climbing,
    title = "Climbing towards {NLU}: {On} Meaning, Form, and Understanding in the Age of Data",
    author = "Bender, Emily M.  and
      Koller, Alexander",
    editor = "Jurafsky, Dan  and
      Chai, Joyce  and
      Schluter, Natalie  and
      Tetreault, Joel",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.463/",
    doi = "10.18653/v1/2020.acl-main.463",
    pages = "5185--5198",
    abstract = "The success of the large neural language models on many NLP tasks is exciting. However, we find that these successes sometimes lead to hype in which these models are being described as {\textquotedblleft}understanding{\textquotedblright} language or capturing {\textquotedblleft}meaning{\textquotedblright}. In this position paper, we argue that a system trained only on form has a priori no way to learn meaning. In keeping with the ACL 2020 theme of {\textquotedblleft}Taking Stock of Where We{'}ve Been and Where We{'}re Going{\textquotedblright}, we argue that a clear understanding of the distinction between form and meaning will help guide the field towards better science around natural language understanding."
}

@article{hogarthFT,
    author = {Ian Hogarth},
    title = {We must slow down the race to god-like {AI}},
    journal = {Financial Times, 12/04/2023},
    year = {}
}

@book{brecht,
    author = {Bertolt Brecht},
    title = {Bertolt Brecht Werke: Schriften 3. Vol. 23.},
    publisher = {Berlin: Aufbau-Verlag},
    year = {1993},
    note = {Translation by Alex Bull}
}

@book{derrida1,
    author = {Jacques Derrida},
    title = {De la Grammatologie},
    publisher = {Les Éditions de Minuit},
    year = {1967}
}

@book{derrida2,
    author = {Jacques Derrida},
    title = {L'Écriture et la Différence},
    publisher = {Éditions du Seuil},
    year = {1967}
}

@book{derrida3,
    author = {Jacques Derrida},
    title = {Le monolinguisme de l'autre: ou la prothèse d'origine},
    publisher = {Éditions Galilée},
    year = {1996}
}

@article{forbesChatGPT,
    author = {Martine Paris},
    title = {ChatGPT Hits 1 Billion Users? ‘{Doubled} In Just Weeks’ Says {OpenAI} {CEO}},
    journal = {Forbes},
    year = {12/04/2025},
    note = {https://www.forbes.com/sites/martineparis/2025/04/12/chatgpt-hits-1-billion-users-openai-ceo-says-doubled-in-weeks/. Accessed: 01/06/2025}
}

@misc{fitz2024hiddenholestopologicalaspects,
      title={Hidden Holes: topological aspects of language models}, 
      author={Stephen Fitz and Peter Romero and Jiyan Jonas Schneider},
      year={2024},
      eprint={2406.05798},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2406.05798}, 
}


@InProceedings{fitz22a,
  title = 	 {The Shape of Words - topological structure in natural language data},
  author =       {Fitz, Stephen},
  booktitle = 	 {Proceedings of Topological, Algebraic, and Geometric Learning Workshops 2022},
  pages = 	 {116--123},
  year = 	 {2022},
  editor = 	 {Cloninger, Alexander and Doster, Timothy and Emerson, Tegan and Kaul, Manohar and Ktena, Ira and Kvinge, Henry and Miolane, Nina and Rieck, Bastian and Tymochko, Sarah and Wolf, Guy},
  volume = 	 {196},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {25 Feb--22 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v196/fitz22a/fitz22a.pdf},
  url = 	 {https://proceedings.mlr.press/v196/fitz22a.html},
  abstract = 	 {This paper presents a novel method, based on the ideas from algebraic topology, for the analysis of raw natural language text. The paper introduces the notion of a word manifold - a simplicial complex, whose topology encodes grammatical structure expressed by the corpus. Results of experiments with a variety of natural and synthetic languages are presented, showing that the homotopy type of the word manifold is influenced by linguistic structure. The analysis includes a new approach to the Voynich Manuscript - an unsolved puzzle in corpus linguistics. In contrast to existing topological data analysis approaches, we do not rely on the apparatus of persistent homology. Instead, we develop a method of generating topological structure directly from strings of words.}
}


@article{leibnizianAnalysis,
	author = {Jennings, R. E. and Chen, Y. and Sahasrabudhe, J.},
	date = {2011/04/01},
	date-added = {2025-06-02 11:56:16 +0100},
	date-modified = {2025-06-02 11:56:16 +0100},
	doi = {10.1007/s11787-011-0027-4},
	id = {Jennings2011},
	isbn = {1661-8300},
	journal = {Logica Universalis},
	number = {1},
	pages = {101--113},
	title = {On a New Idiom in the Study of Entailment},
	url = {https://doi.org/10.1007/s11787-011-0027-4},
	volume = {5},
	year = {2011},
	bdsk-url-1 = {https://doi.org/10.1007/s11787-011-0027-4}
}


@misc{fSadri,
    author = {Fariba Sadri},
    title = {Logic and Maths for Computing Lecture Notes},
    year = {2025},
    note = {Imperial MSc Computing Module}
}

@conference{Cederquist,
    title = "Entailment relations and distributive lattices",
    abstract = "To any entailment relation [Sco74] we associate a distributive lattice. We use this to give a construction of the product of lattices over an arbitrary index set, of the Vietoris construction, of the embedding of a distributive lattice in a boolean algebra, and to give a logical description of some spaces associated to mathematical structures.",
    keywords = "IR-56168, EWI-985",
    author = "Sam Buss and J.G. Cederquist and Thierry Coquand and Petr Hajek and Pavel Pudlak",
    note = "Imported from DIES; Logic Colloquium 1998 ; Conference date: 09-08-1998 Through 15-08-1998",
    year = "2000",
    month = jan,
    language = "Undefined",
    pages = "110--123"
}

@article{Evans2018,
    author = {Evans, Richard and Saxton, David and Amos, David and Kohli, Pushmeet and Grefenstette, Edward},
    year = {2018},
    month = {02},
    pages = {},
    title = {Can Neural Networks Understand Logical Entailment?},
    doi = {10.48550/arXiv.1802.08535}
}

@inproceedings{poliak-2020-survey,
    title = "A survey on Recognizing Textual Entailment as an {NLP} Evaluation",
    author = "Poliak, Adam",
    editor = "Eger, Steffen  and
      Gao, Yang  and
      Peyrard, Maxime  and
      Zhao, Wei  and
      Hovy, Eduard",
    booktitle = "Proceedings of the First Workshop on Evaluation and Comparison of NLP Systems",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.eval4nlp-1.10/",
    doi = "10.18653/v1/2020.eval4nlp-1.10",
    pages = "92--109",
    abstract = "Recognizing Textual Entailment (RTE) was proposed as a unified evaluation framework to compare semantic understanding of different NLP systems. In this survey paper, we provide an overview of different approaches for evaluating and understanding the reasoning capabilities of NLP systems. We then focus our discussion on RTE by highlighting prominent RTE datasets as well as advances in RTE dataset that focus on specific linguistic phenomena that can be used to evaluate NLP systems on a fine-grained level. We conclude by arguing that when evaluating NLP systems, the community should utilize newly introduced RTE datasets that focus on specific linguistic phenomena."
}

@InCollection{sep-montague-semantics,
	author       =	{Janssen, Theo M. V. and Zimmermann, Thomas Ede},
	title        =	{{Montague Semantics}},
	booktitle    =	{The {Stanford} Encyclopedia of Philosophy},
	editor       =	{Edward N. Zalta and Uri Nodelman},
	howpublished =	{\url{https://plato.stanford.edu/archives/spr2025/entries/montague-semantics/}},
	year         =	{2025},
	edition      =	{{S}pring 2025},
	publisher    =	{Metaphysics Research Lab, Stanford University}
}

@article{estival1997,
author = {Estival, Dominique},
year = {1997},
month = {12},
pages = {375-379},
title = {Karen Sparck Jones and Julia R. Galliers, Evaluating Natural Language Processing Systems: An Analysis and Review. Lecture Notes in Artificial Intelligence 1083},
volume = {12},
journal = {Machine Translation},
doi = {10.1023/A:1007918307730}
}

@inproceedings{white-etal-2017-inference,
    title = "Inference is Everything: Recasting Semantic Resources into a Unified Evaluation Framework",
    author = "White, Aaron Steven  and
      Rastogi, Pushpendre  and
      Duh, Kevin  and
      Van Durme, Benjamin",
    editor = "Kondrak, Greg  and
      Watanabe, Taro",
    booktitle = "Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = nov,
    year = "2017",
    address = "Taipei, Taiwan",
    publisher = "Asian Federation of Natural Language Processing",
    url = "https://aclanthology.org/I17-1100/",
    pages = "996--1005",
    abstract = "We propose to unify a variety of existing semantic classification tasks, such as semantic role labeling, anaphora resolution, and paraphrase detection, under the heading of Recognizing Textual Entailment (RTE). We present a general strategy to automatically generate one or more sentential hypotheses based on an input sentence and pre-existing manual semantic annotations. The resulting suite of datasets enables us to probe a statistical RTE model{'}s performance on different aspects of semantics. We demonstrate the value of this approach by investigating the behavior of a popular neural network RTE model."
}

@article{CooperFracas,
author = {Cooper, Robin and Milward, David and Pinkal, Manfred and Poesio, Massimo and Pulman, Steve and D, Deliverable},
year = {1996},
month = {02},
pages = {},
title = {A Strategy for Building a Framework for Computational Semantics (The Way Forward)}
}

@inproceedings{dzikovska-etal-2013-semeval,
    title = "{S}em{E}val-2013 Task 7: The Joint Student Response Analysis and 8th Recognizing Textual Entailment Challenge",
    author = "Dzikovska, Myroslava  and
      Nielsen, Rodney  and
      Brew, Chris  and
      Leacock, Claudia  and
      Giampiccolo, Danilo  and
      Bentivogli, Luisa  and
      Clark, Peter  and
      Dagan, Ido  and
      Dang, Hoa Trang",
    editor = "Manandhar, Suresh  and
      Yuret, Deniz",
    booktitle = "Second Joint Conference on Lexical and Computational Semantics (*{SEM}), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation ({S}em{E}val 2013)",
    month = jun,
    year = "2013",
    address = "Atlanta, Georgia, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/S13-2045/",
    pages = "263--274"
}

@inproceedings{marelli-etal-2014-sick,
    title = "A {SICK} cure for the evaluation of compositional distributional semantic models",
    author = "Marelli, Marco  and
      Menini, Stefano  and
      Baroni, Marco  and
      Bentivogli, Luisa  and
      Bernardi, Raffaella  and
      Zamparelli, Roberto",
    editor = "Calzolari, Nicoletta  and
      Choukri, Khalid  and
      Declerck, Thierry  and
      Loftsson, Hrafn  and
      Maegaard, Bente  and
      Mariani, Joseph  and
      Moreno, Asuncion  and
      Odijk, Jan  and
      Piperidis, Stelios",
    booktitle = "Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14)",
    month = may,
    year = "2014",
    address = "Reykjavik, Iceland",
    publisher = "European Language Resources Association (ELRA)",
    url = "https://aclanthology.org/L14-1314/",
    pages = "216--223",
    abstract = "Shared and internationally recognized benchmarks are fundamental for the development of any computational system. We aim to help the research community working on compositional distributional semantic models (CDSMs) by providing SICK (Sentences Involving Compositional Knowldedge), a large size English benchmark tailored for them. SICK consists of about 10,000 English sentence pairs that include many examples of the lexical, syntactic and semantic phenomena that CDSMs are expected to account for, but do not require dealing with other aspects of existing sentential data sets (idiomatic multiword expressions, named entities, telegraphic language) that are not within the scope of CDSMs. By means of crowdsourcing techniques, each pair was annotated for two crucial semantic tasks: relatedness in meaning (with a 5-point rating scale as gold score) and entailment relation between the two elements (with three possible gold labels: entailment, contradiction, and neutral). The SICK data set was used in SemEval-2014 Task 1, and it freely available for research purposes."
}

@inproceedings{williams-etal-2018-broad,
    title = "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference",
    author = "Williams, Adina  and
      Nangia, Nikita  and
      Bowman, Samuel",
    editor = "Walker, Marilyn  and
      Ji, Heng  and
      Stent, Amanda",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N18-1101/",
    doi = "10.18653/v1/N18-1101",
    pages = "1112--1122",
    abstract = "This paper introduces the Multi-Genre Natural Language Inference (MultiNLI) corpus, a dataset designed for use in the development and evaluation of machine learning models for sentence understanding. At 433k examples, this resource is one of the largest corpora available for natural language inference (a.k.a. recognizing textual entailment), improving upon available resources in both its coverage and difficulty. MultiNLI accomplishes this by offering data from ten distinct genres of written and spoken English, making it possible to evaluate systems on nearly the full complexity of the language, while supplying an explicit setting for evaluating cross-genre domain adaptation. In addition, an evaluation using existing machine learning models designed for the Stanford NLI corpus shows that it represents a substantially more difficult task than does that corpus, despite the two showing similar levels of inter-annotator agreement."
}

@article{Khot_Sabharwal_Clark_2018, title={SciTaiL: A Textual Entailment Dataset from Science Question Answering}, volume={32}, url={https://ojs.aaai.org/index.php/AAAI/article/view/12022}, DOI={10.1609/aaai.v32i1.12022}, number={1}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Khot, Tushar and Sabharwal, Ashish and Clark, Peter}, year={2018}, month={Apr.} }

@InProceedings{shajalal,
author="Shajalal, Md
and Atabuzzaman, Md.
and Baby, Maksuda Bilkis
and Karim, Md. Rezaul
and Boden, Alexander",
editor="M, Anand Kumar
and Chakravarthi, Bharathi Raja
and B, Bharathi
and O'Riordan, Colm
and Murthy, Hema
and Durairaj, Thenmozhi
and Mandl, Thomas",
title="Textual Entailment Recognition with Semantic Features from Empirical Text Representation",
booktitle="Speech and Language Technologies for Low-Resource Languages ",
year="2023",
publisher="Springer International Publishing",
address="Cham",
pages="183--195",
abstract="Textual entailment recognition is one of the basic natural language understanding (NLU) tasks. Understanding the meaning of sentences is a prerequisite before applying any natural language processing (NLP) techniques to automatically recognize the textual entailment. A text entails a hypothesis if and only if the true meaning and intent of the hypothesis follows the text. Classical approaches generally utilize the feature value of each word from word embedding to represent the sentences. In this paper, we propose a new framework to identify the textual entailment relationship between text and hypothesis, thereby introducing a new semantic feature focusing on empirical threshold-based semantic text representation. We employ an element-wise Manhattan distance vector-based feature that can identify the semantic entailment relationship between the text-hypothesis pair. We carried out several experiments on a benchmark entailment classification (SICK-RTE) dataset. We train several machine learning (ML) algorithms applying both semantic and lexical features to classify the text-hypothesis pair as entailment, neutral, or contradiction. Our empirical sentence representation technique enriches the semantic information of the texts and hypotheses found to be more efficient than the classical ones. In the end, our approach significantly outperforms known methods in understanding the meaning of the sentences for the textual entailment classification task.",
isbn="978-3-031-33231-9"
}

@phdthesis{pavlick2017,
    author = {Ellie Pavlick},
    title = {Compositional Lexical Entailment for Natural Language Inference},
    school = {University of Pennsylvania},
    year = {2017}
}

@misc{sanwal2024evaluatinglargelanguagemodels,
      title={Evaluating Large Language Models Using Contrast Sets: An Experimental Approach}, 
      author={Manish Sanwal},
      year={2024},
      eprint={2404.01569},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.01569}, 
}

@misc{xie2019visualentailmentnoveltask,
      title={Visual Entailment: A Novel Task for Fine-Grained Image Understanding}, 
      author={Ning Xie and Farley Lai and Derek Doran and Asim Kadav},
      year={2019},
      eprint={1901.06706},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1901.06706}, 
}