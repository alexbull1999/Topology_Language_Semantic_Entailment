\documentclass[12pt,twoside]{report}

% some definitions for the title page
\newcommand{\reporttitle}{asdfasdf}
\newcommand{\reportauthor}{Your name}
\newcommand{\supervisor}{Name of supervisor}
\newcommand{\reporttype}{Type of Report/Thesis}
\newcommand{\degreetype}{Type of degree} 

% load some definitions and default packages
\input{includes}

% load some macros
\input{notation}

% load title page
\begin{document}
\input{titlepage}


% page numbering etc.
\pagenumbering{roman}
\clearpage{\pagestyle{empty}\cleardoublepage}
\setcounter{page}{1}
\pagestyle{fancy}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\vspace*{-\fill}
\begin{abstract}
Semantic entailment, the question of whether a hypothesis $h$, can be inferred from a text $t$, is a core part of the field of Natural Language Processing (NLP), and one that is key to many important tasks including ``QA [question answering], IR [information retrieval], text summarization, machine translation, information extraction, and paraphrasing.'' \cite{PARAMASIVAM20229644} 
\newline \par
Semantic entailment is also a fundamental task for large language models (LLMs), on which many people are beginning to rely on for knowledge on a daily basis, thus becoming an ever more integral part of society. It is evident that for LLMs to provide reliable, robust answers to questions and meet the expectations of users, an ability to accurately understand questions of semantic entailment is crucial. Yet, given the fact that LLMs are often ``trained on text alone, without additional grounding,'' \cite{merrill-etal-2022-entailment} where training objectives focus on predicting missing words, many argue that this ``language modelling task, because it only uses form as training data, cannot in principle lead to learning of meaning.'' \cite{bender-koller-2020-climbing} \newline \par
In this thesis, we seek to bridge this gap and improve the performance and reliability of LLMs by imbuing them with the concept of semantic entailment during their training. We apply highly novel approaches for understanding semantic entailment through Topological Data Analysis (TDA) to study the topology of language, to develop a new metric that can robustly measure entailment, based theoretically on the concepts of entailment cones in hyperbolic geometric space. Subsequently, we mould the new entailment metric into a differentiable function that we inject as a regularizer into the training process of an LLM; where an additional optimization goal during the LLM's training is to maintain high entailment scores. We compare our `entailment-enhanced' LLM against various SOTA-models on core entailment challenges and demonstrate that our method results in an improvement of at least XX\% F1-score compared to the next best model, across all datasets. 



\end{abstract}


\section*{Acknowledgments}
Comment this out if not needed.

\clearpage{\pagestyle{empty}\cleardoublepage}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%--- table of contents
\fancyhead[RE,LO]{\sffamily {Table of Contents}}
\tableofcontents 


\clearpage{\pagestyle{empty}\cleardoublepage}
\pagenumbering{arabic}
\setcounter{page}{1}
\fancyhead[LE,RO]{\slshape \rightmark}
\fancyhead[LO,RE]{}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Introduction}
\section{Motivation of the Thesis}
Language lies at the heart of the upsurge in Artifical Intelligence over the last 10 years. The arrival of Large Language Models (LLMs) like ChatGPT who can almost flawlessly reproduce language, discourse on any subject, and answer even the most complex of questions with relative assuredness has been transformative across industry and academia alike. Indeed, the prowess with which such LLMs have seemingly mastered language has led, particularly amongst mainstream media, to comparisons with ``god-like'' technology. \cite{hogarthFT} Investigations into the nature of language through the lens of topology, and the ability for LLMs to truly master language, form the core motivation for this thesis, which is discussed in the following section. 


\subsection{What is the meaning of language?}

Whilst this is a Computer Science thesis, and one that we believe will lead to significant novel discoveries that will materially improve the performance of LLMs in semantic entailment tasks, the fundamental motivation behind the topic is the same question that motivated my undergraduate dissertation in Modern and Medieval Languages; namely - what does it mean to \textbf{\textit{truly}} speak a language. \newline \par

I began that dissertation with a quote from Bertolt Brecht during his exile in the United States, that I believe is equally relevant for this thesis:
\begin{quote}
    I haven't the slightest hope of ever learning colloquial American English. It's certainly not for a lack of trying [...] It's something else that evades me. [...] In discussions, I'm not able to say what I want, just what I can. [...] One could assume that this confusing state would be temporary [...], but that is sadly wishful thinking. It's not that I'm unable to grasp the vocabulary, nor the syntactical or grammatical knowledge. Rather, what I cannot grasp is a certain linguistic \textit{Habitus}, which I simply do not see any possibility of learning.\cite{brecht}
\end{quote}

Brecht's experience of fluency of alienation from the linguistic \textit{habitus} of a foreign language, no matter how fluently it is spoken, is one that would resonate with any linguist. Yet, we ask and, indeed, expect LLMs to inhabit the linguistic \textit{habitus} of all languages at the same time with expert accuracy. \newline \par

In addition to an expectation of fluency and familiarity with our language, we also expect LLMs to understand and answer our questions in the same reasonable and reliable manner as we would expect from a subject matter expert. To fulfil these expectations, the ability for LLMs to understand semantic `meaning' and entailment is key. This is, however, not the case today. LLMs are commonly ``trained on text alone, without additional grounding''\cite{merrill-etal-2022-entailment}, with the missing-word prediction training tasks unable ``in principle [to] lead to learning of meaning.''\cite{bender-koller-2020-climbing} \newline \par 
While Bender et al. cast doubt on the ability of LLMs to truly understanding meaning, and hence to robustly evaluate more challenging semantic entailment tasks, these are also something that humans can often falter with. For example, given the premise ``All men are created equal'' with contextual knowledge of its origin in the US Declaration of Independence, multiple `valid' interpretations of the hypothesis ``Every person has the same inherent value'' are possible, each with very different ramifications:
\begin{enumerate}
    \item \textit{Contradiction}: `Men' in 1776 deliberately excluded women, enslaved people, Indigenous peoples.
    \item \textit{Entailment}: Despite historical limitations, the principle of the hypothesis is universal and should be understood as such.
\end{enumerate}

The inherently uncertain, fallible and \textit{individual} nature of language that these examples have attempted to exemplify is one best summarised by Jacques Derrida \cite{derrida1, derrida2, derrida3}, who maintains that the meaning of all language, whether speech or writing, is created through unstable, spatial and temporal relations between signifiers, that he terms différance - with every language-speaker caught up in the matrix of differences through which language functions. \newline \par

A core driver of this thesis then, is to investigate whether - contrary to the philosophical arguments given above - we can use concepts from the field of Topological Data Analysis to find an objective, \textit{universal} mathematical representation of language in which the concept of entailment can be robustly defined, modelled, and imbued into an LLM training regime, in order to improve its performance.


\subsection{The importance of understanding language in the age of Artificial Intelligence}
The questions raised in the previous section are of far greater practical significance than the intellectual curiosities that they may appear to be on the surface. Since the advent of LLMs only a few years ago, society has grown rapidly reliant on them - ChatGPT alone is forecast to have 1 billion users, almost 10\% of the world's population, by the end of 2025 at the latest. \cite{forbesChatGPT} \newline \par

Given this trajectory towards dependency on the outputs of LLMs, where such tools are consulted in the making of critical personal, business, or even political decisions, the safety and trustworthiness of LLM responses provided is of essential importance. Yet this is precisely where we have the least understanding and control of LLMs themselves. As explained by Fitz et al. (2024) \cite{fitz2024hiddenholestopologicalaspects}, ``as of now it is still a mystery why certain behaviours emerge in large language models, and little is understood about the structure of their representation manifolds.'' Many elements of how LLMs function still remain a `black box'. We interact with them at the level of their textual output, in which ``the natural topological structure of [the] language embeddings, which define the ``thoughts'' of the system, is lost'' \cite{fitz2024hiddenholestopologicalaspects}. For example, Figure 1.1, taken from Fitz (2022), \cite{fitz22a} shows a graph projection of vector space embeddings of word tokens from French and English. The differences in shape are striking, but the reasons for these differences are still unclear. \newline

\begin{figure}[tb]
\centering
\includegraphics[width = 1\hsize]{./figures/graph_projection_fitz}
\caption{A graph projection of vector space embeddings of word tokens derived from corpora of French (left) and English (right).}
\label{fig:EmbeddingsFrenchEnglish}
\end{figure}

\par
This thesis hence seeks to conduct further investigations into the topology and geometry of the vector embeddings of language in LLMs. Such investigations are of manifold importance: the more we understand about the topology and geometry of LLMs, the better we can understand why they exhibit certain behaviours, and how we can improve their efficiency and parametrisation, potentially enabling smaller, more compressed models \cite{fitz2024hiddenholestopologicalaspects}. \newline \par

We, however, will focus specifically on understanding how relationships of semantic entailment are projected into the vector spaces that allow LLMs to `think'. We aim to develop an entailment metric that, when implemented as a regularizer in LLM training, will lead to better LLM performance on semantic entailment tasks. In doing so, we may also uncover potential answers to some of the more philosophical questions posed in the previous section, relating to what it means to speak a language, for humans and for AI. 

\section{Research Aim And Contributions}

The aim of this project is to understand the topology of language in LLM vector spaces and derive therefrom a robust expression that characterises the notion of semantic entailment, which, when used as a regularizer in LLM training, can improve performance on semantic and visual entailment tasks.  \newline \par

To achieve this aim, we make the following contributions: 

\begin{enumerate}
    \item \textbf{We implement topological data analysis (TDA) techniques (persistent homology, MAPPER) to investigate topological relationships between entailed, contradictory, and neutral premise-hypothesis pairs.} In Chapter X, we undertake this for semantic entailment, using the Stanford Natural Language Inference (SNLI) dataset. In Chapter (X+1), we replicate this task for a visual entailment dataset (SNLI-VE), where premises are given in the form of images rather than phrases.
    \item \textbf{We develop a robust mathematical expression for entailment using concepts from hyperbolic geometry - namely hyperbolic entailment cones}, from which we derive an entailment metric that can produce accurate entailment scores across semantic and visual entailment challenges; and be used to compare existing LLM performances on such tasks
    \item \textbf{We train an LLM with an `entailment regularizer'}, based on the entailment expression in 2., and demonstrate that it has superior performance on semantic and visual entailment tasks vs. SOTA benchmarks 
    \item \textbf{We reason briefly on the philosophical and linguistic implications of our findings}, including what our findings imply about linguistic theories such as Chomsky's universal grammar. 
\end{enumerate}


\section{Report Structure}
Chapter 2 provides an overview of the relevant theoretical and practical background to this work. This includes an outline of the logic and theory underpinning questions of entailment (Section 2.1), and a survey of major existing approaches to both semantic and visual entailment within the fields of NLP and computer vision, respectively (Section 2.2). We also provide a brief grounding in key concepts from Topological Data Analysis (TDA) and hyperbolic geometry for the unfamiliar reader (Section 2.3), and highlight the handful of existing  applications of TDA to language and LLMs, upon which this thesis builds. \par   \quad In Chapter 3, we develop the core theoretical element of this thesis, introducing the topological mapping of premise-hypothesis pairs, and the development of a metric to measure semantic entailment. \par 
\quad Chapter 4 presents experimental results displaying the robustness of the entailment metric across both semantic and visual entailment datasets, and evaluates the performance of SOTA LLMs to detect entailment, compared to our metric. \par
\quad Chapter 5 outlines the approach taken to extend our expression for entailment into a differentiable function that we implement as a regularizer in the training of an LLM, and demonstrates, through experiments, its superior performance against both SOTA LLMs, and other benchmark methods used in entailment challenges. \par
\quad Finally, Chapter 6 summarizes the contributions of this thesis, discusses potential avenues for future work suggested by our findings, and attempts to provide an answer to some of the more philosophical and linguistic questions raised by this research before concluding the thesis.




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Background and Related Work}
This chapter presents an overview of existing progress and key related works in the fields of semantic and visual entailment, before providing a minimum theoretical grounding in the primary Topological Data Analysis (TDA) and Hyperbolic Geometry methodologies that will be used throughout this thesis. \newline \par

Section 2.1 focuses on logical representations of entailment tasks, which help to provide the theoretical framework for how we practically apply topological data analysis (TDA) methods in this thesis. \par \quad Section 2.2 introduces key practical datasets that have been used to experiment with semantic and visual entailment challenges in the NLP and Computer Vision communities respectively, alongside the metrics used, and varying approaches that have already been adopted.  \par \quad Finally, section 2.3 introduces two key Topological Data Analysis (TDA) methodologies - Persistent Homology and MAPPER - before discussing their relevance to language through exploring theoretical papers relating to the geometry of language. Section 2.3 closes by surveying existing practical applications of TDA in NLP, before briefly discussing the benefits of Euclidean vs. Hyperbolic Geometry in the context of semantic entailment - a question that is highly relevant for the practical approach we decide to adopt in the following chapters of this thesis. 

\section{Logical Representations of Entailment}

This thesis is an investigation of the Topology of Language for Semantic Entailment in the context of LLMs and, naturally, this was the focus of the introduction in Chapter 1. But to understand how semantic entailment can be captured through topological methods, we first need to examine its foundations in formal logic. Semantic entailment is, of course, fundamentally an exercise in logic. Natural language sentences can be broken down into their fundamental logical constituents and evaluated in Conjunctive Normal Form (CNF) through the language of propositional or predicate logic - and indeed this is one of the existing approaches to Semantic Entailment tasks that will be outlined in Section 2.2. As a simple example \cite{fSadri}, take the premises: 
\begin{flushleft}
\text{`If there are national elections, either the Tory party wins or the Labour party wins.'} \\
\text{`If the unions do not support the Labour party then it does not win.'} \\
\text{`There are national elections.'}

\end{flushleft}

\par and the hypothesis:
\begin{flushleft}
If the Tory party does not win then the unions
support the Labour party?    
\end{flushleft}

Using `E' to stand for elections, `L' to stand for a Labour victory, `T' to stand for a Tory victory, and `U' to stand for unions supporting labour, we can easily remodel these natural language statements into CNF: \newline 
\begin{align*}
\text{Premise:} \quad & E \rightarrow L \lor T, \quad \lnot U \rightarrow \lnot L, \quad E \\
\text{Conclusion:} \quad & \lnot T \rightarrow U
\end{align*}

From which we can easily prove that the conclusion is entailed by the premise, since in all cases where $\lnot T$ is true, we can see from the first WFF of the premise that $L$ must be true, and hence from the second that $U$ must also be true. \newline \par

This relationship between semantic entailment and logical entailment is important, because multiple works have derived `idioms' of entailment from logical analysis, which, as we shall now outline, provide justification for this thesis' hypothesis that topological features in embedding spaces can capture semantic entailment relationships. 

\subsection{Entailment as a Subsumption Relationship of Hypergraphs}

Jennings et al. \cite{leibnizianAnalysis} formulate a novel approach to entailment, using Leibnizian analysis to demonstrate how logic entailment can be demonstrated through subsumption relationships between hypergraphs. Before discussing their work and its relevance to this thesis, we first outline several key concepts for the unfamiliar reader: \newline
\begin{itemize}
    \item \textbf{Possible Worlds}. In logic, a possible world represents one possibility of truth values. For example, if we have a simple logical premise represented by literals $p$ (meaning, say, that it is raining), and $q$ (meaning, say, that the ground is wet), there are four possible worlds:
    \begin{enumerate}
        \item $w_1$: both p and q are true
        \item $w_2$: p is true, q is false
        \item $w_3$: p is false, q is true
        \item $w_4$: both p and q are false
    \end{enumerate}
    \item \textbf{Powersets}. The powerset of possible worlds, denoted by Jennings et al. as $\wp(U)$ \cite{leibnizianAnalysis}, is the set of all possible sets, i.e. representing the universe in a full propositional model. The subset $\{w_1, w_2\}$ within $\wp(U)$ would, in this example, represent all worlds in which ``it is raining'' is true. 
    \item \textbf{Hypergraphs}. Borrowing the defintion directly from Jennings et al. \cite{leibnizianAnalysis}, ``a hypergraph $H$ is a pair $H=(X, E)$ where $X$ is a set of elements, called nodes or vertices, and $E$ is a non-empty set of non-empty subsets of $X$, each of which is called a (hyper-)edge. [...] Conventionally, we can write $H$ as a collection of edges, i.e. $H=\{E_1, E_2, ..., E_n\}$, where $\forall i, 1 \leq i \leq n, E_i \in X$. 
    \item \textbf{Atomic Constituents}. An atomic constituent is the simplest, irreducible form of a logical expression - i.e., a literal in propositional logic. By this definition CNF can be viewed as a disjunction of atoms.
\end{itemize}

With this background, we can summarize the key insights outlined by Jennings et al. \cite{leibnizianAnalysis}, and their relevance for a topological investigation of semantic entailment in this thesis. We refer the interested reader to \cite{leibnizianAnalysis} for the mathematical proofs of these insights. \newline \par \quad 
1. Since `every sentence has a finite analysis into its conjunctive normal form [...], semantically, then, every sentence of that language can be represented as a simple hypergraph, $H$, on the powerset of a universe of states'. \newline \par
This is particularly relevant in the context of this thesis' topological approach, since hypergraph representations can naturally embed logical relationships into a geometric form. \newline \par \quad
2. An entailment relationship $\alpha \models \beta$, corresponds to a subsumption relationship between two hypergraphs on $\wp(U)$, such that $H_{\alpha} \sqsubseteq H_{\beta}$. The subsumption relationship is defined as true if \cite{leibnizianAnalysis}: 
$$
\forall H, H' \in \mathbb{H},\; H \sqsubseteq H',
\text{ if and only if }
\forall E' \in H',\; \exists E \in H \text{ such that } 
\forall e \in E,\; \exists e' \in E' : e \leq e'  
$$ 

where $\mathbb{H}$ is a set of \textit{simple} hypergraphs such that $\mathbb{H} \subseteq \wp\wp(U)$. \newline \par

Figure 2.1 demonstrates a trivial example of this, where a premise $(p \lor q \lor r) \land (\neg s \lor q) $  is modelled by the hypergraph $H_A$, whilst a conclusion $q \lor r$ is modelled by hypergraph $H_B$.

\begin{figure}[H]
\centering
\includegraphics[width = 1\hsize]{./figures/HypergraphIntro.drawio.png}
\caption{A hypergraph representation of $(p \lor q \lor r) \land (\neg s \lor q)$ in $H_A$, and $q \lor r$ in $H_B$}
\label{fig:Hypergraphs}
\end{figure}

Following the definition given above, for the conclusion $H_B$ to be entailed by the premise $H_A$, every hyperedge of $H_B$ (in this case just $e_{b1}$), must be `underwritten' by at least one hyperedge in $H_A$. We can clearly see this is the not the case, and the conclusion is not entailed by the premise, since $H_A$ has no hyperedge containing just $\{q, r\}$. \newline

The entailment relationship described above is also highly relevant to this thesis, as it provides a theoretical foundation according to which we can look for entailment relationships in our topological investigations of language. \newline \par

\quad 3. The definition of entailment relationships via subsumption leads to the emergence of an algebraic lattice structure; namely that $\langle\mathbb{H}, \sqsubseteq\rangle$ is a lattice \cite{leibnizianAnalysis}. The connection between entailment relations and distributive lattices is further developed by Cederquist and Coquand \cite{Cederquist}, who establish a direct bridge between the abstract logical system of entailment relations and topological spaces, through the use of distributive and normal lattices. This lattice structure has the following important tenets:
\begin{enumerate}
    \item \textbf{Partial Order}: The subsumption relation creates a partial order between the hypergraphs involved. For example, if $H_A \sqsubseteq H_B$, then we can colloquially think of $H_A$ as `containing more information' or being `higher' in the lattice than $H_B$
    \item \textbf{Lattice Operations}: Given any two hypergraphs $H_A$ and $H_B$, we can state that their \textit{join} $(H_A \lor H_B)$ is the hypergraph representing the weakest formula that \textbf{both entail}; whilst their \textit{meet} $(H_A \land H_B)$ is the hypergraph representing the strongest formula that \textbf{entails both}
    \item \textbf{De-Morgan Structure For Negation}: Logical negation can be accomplished using the blocker function $\tau$, which allows the following logical rules to hold true:
    \begin{itemize}
        \item $\tau(\tau(H_A)) = H_A$, i.e. double negation
        \item $H_A \sqsubseteq H_B \iff \tau(H_B) \sqsubseteq \tau(H_A)$, i.e. order reversal under negation
    \end{itemize}
\end{enumerate}

These findings are key for several reasons. Firstly, `the semantic idiom that hypergraph-theory affords reveals a hierarchy of lattices capable of representing entailments of every finite degree' \cite{leibnizianAnalysis}. Secondly, lattices themselves provide a bridge from discrete logical topographic structures (i.e. hypergraphs), to a continuous geometric space, where notions of `height' (how general vs. how specific a formula is), `distance' (how many steps in the lattice separate two formulae), and `directions' (moving up the lattice, as generalization, and moving down, as specialization) are all present. Combined, these two principles lay the theoretical foundation for this thesis' hypothesis that relationships of semantic entailment should be able to be detected and measured through topological analysis. \newline \par

The lattice structure should, in theory, enable the logical relationships of entailment to be preserved when we move from semantics in words and phrases across to their vector space embeddings in LLMs; while the partial order features of lattices capture the asymmetry of entailment, where $A \rightarrow B \neq B \rightarrow A$. Finally, we hypothesise - and aim to prove experimentally in the following chapters - that the height, distance and directional metrics of lattices can be analysed through topological data analysis, to measure and analyse semantic entailment relationships.


\subsection{From Logical to Semantic Entailment}

The theoretical and mathematical studies of entailment above focus on logical entailment. While logical entailment operates on formal symbols with fixed meaning, textual entailment in natural language - incorporating the lexical and syntactic meaning of words, phrases, and sentences - must grapple with the often ambiguous and context-dependent nature of language outlined in the introduction to this thesis. \newline \par

Some interesting work has already been undertaken studying the ability of neural networks and LLMs to tackle tasks involving logical entailment and textual entailment in natural language. Evans et al. \cite{Evans2018} developed a new neural network architecture termed a `PossibleWorldNet', that was able to achieve 96\% accuracy on tasks involving entailment in propositional logic. Such high performance suggested that the network was able to learn the structural patterns of entailment. As the authors state, for propositional logic, ``the problem of determining whether an entailment holds is a purely structural sequence-based problem: to evaluate whether an entailment is true, only the meaning of - or inference rules governing - the connectives is relevant. Everything else only has meaning via its place in the structure specified by an expression.'' \cite{Evans2018} \newline \par

The `PossibleWorldNet' architecture developed by Evans et al. is a variant of a TreeNet architecture that evaluates pairs of propositional logic formulae in different `possible worlds'. ``To evaluate whether $A \models B$, the PossibleWorldNet generates a set of imagined “worlds”, and then evaluates A and B in each of those worlds. It is a form of ``convolution over possible worlds'', [where] the quality of the model increases steadily as we increase the number of imagined worlds.'' \cite{Evans2018} This architecture significantly outperformed conventional architectures, such as transformers (by 40-50\%), and convolutional networks (by roughly 40\%). The authors suggest that the poor performance of these models is likely due to the inability to capture with sufficient precision the correct hierarchical structures that exist within logical expression. \newline \par

While these findings are strictly in the field of logical entailment, which ``unlike textual entailment, depends only on the meaning of logical operators, and of the place particular arbitrarily-named variables hold within a structure'' \cite{Evans2018}, these results do have an important implication for the textual entailment tasks we shall explore in this thesis. As is pointed out in \cite{Evans2018}, current neural models, including the transformer architecture that most LLMs are built on, can often fail to understand the structure of sentences they are meant to evaluate. For example, Bowman et al. \cite{bowman2015} demonstrate how all neural models they tested wrongly classified the premise ``\textit{A man wearing padded arm protection is being bitten by a German shepherd dog}'' and conclusion ``\textit{A man bit a dog}'' as an entailment relationship, instead of as a contradiction. Given this, Evans et al. emphasise the importance of ``isolating the purely structural sub-problems'' involved in questions of entailment, and claim that ``only networks that can reliably predict entailmetn in a purely formal setting, such as propositional (or first-order) logic, will be capable of getting these sorts of examples consistently correct.'' \cite{Evans2018}. This reinforces the importance of any entailment metric developed by this thesis to be built on the theoretical foundations of first-order logic, as is enabled by the lattice-based idiom of entailment that we explored in the previous section. \newline \par

Progressing from logical entailment to focus on natural language semantics, recent work by Merrill et al., 

Lexical entailment semantics -- theoretical with some practical demonstration under stringent assumptions

But on actual key datasets performance is ... Examine in more detail in next section where LLM performance (approximated by BERT based neural models) achieved only ... \% accuracy. Indeed, other AI models did not perform much better...  explore in enxt section...





\section{Practical Progress in Semantic and Visual Entailment}
\subsection{Semantic Entailment}
Common approaches developed to solve challenges related to semantic entailment, such as those posed in the PASCAL \cite{dagan2006} or Stanford Natural Language Inference (SNLI) \cite{bowman2015} datasets, typically fall into one or several of the following categories \cite{PARAMASIVAM20229644}:
\begin{itemize}
    \item Lexical approaches, that focus on the linguistic information of input surface strings, without considering syntactic or semantic properties
    \item Semantic approaches, which consider the meaning of the text in broader context to evaluate entailment, as opposed to only considering the input surface strings as in the lexical approach
    \item Logical approaches, where a logical representation language is used to determine entailment
    \item AI approaches, where entailment models are built to recognize entailment, with classifiers used to determine if a text-hypothesis pair of inputs results in entailment 
\end{itemize}
\subsection{Visual Entailment}
\section{Topology of Language}
Theoretical approaches followed by  practical?
\subsection{Topological Data Analysis (TDA)}
\subsubsection{Persistent Homology}
\subsubsection{MAPPER}
\subsection{TDA applied to Language}
\subsubsection{Fractal Geometry of Language}
\subsubsection{Intrinsic Dimensionality}
\subsubsection{Practical Applications of TDA in NLP}
\subsection{Euclidean vs. Hyperbolic Geometry for Entailment Mappings}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Project Plan}
Chapter for Background Interim Report only, for second marker feedback




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Approach, 
Experimental Setup and Method}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Experimental Results and Discussion}
The results are very interesting in Jones 2019.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Conclusion}


%% bibliography
\bibliographystyle{unsrt}
\bibliography{References}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter*{Declarations}




\end{document}