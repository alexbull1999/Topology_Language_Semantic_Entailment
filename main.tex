\documentclass[12pt,twoside]{report}

% some definitions for the title page
\newcommand{\reporttitle}{asdfasdf}
\newcommand{\reportauthor}{Your name}
\newcommand{\supervisor}{Name of supervisor}
\newcommand{\reporttype}{Type of Report/Thesis}
\newcommand{\degreetype}{Type of degree} 

% load some definitions and default packages
\input{includes}

% load some macros
\input{notation}

% load title page
\begin{document}
\input{titlepage}


% page numbering etc.
\pagenumbering{roman}
\clearpage{\pagestyle{empty}\cleardoublepage}
\setcounter{page}{1}
\pagestyle{fancy}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\vspace*{-\fill}
\begin{abstract}
Semantic entailment, the question of whether a hypothesis $h$, can be inferred from a text $t$, is a core part of the field of Natural Language Processing (NLP), and one that is key to many important tasks including question answering, information retrieval, text summarization, machine translation, information extraction, and paraphrasing. \cite{PARAMASIVAM20229644} 
\newline \par
Semantic entailment is also a fundamental task for large language models (LLMs), on which many are beginning to rely on for knowledge on a daily basis, thus becoming an ever more integral part of society. For LLMs to provide reliable, robust answers to questions and meet the expectations of users, an ability to accurately understand questions of semantic entailment is crucial. Yet, given the fact that LLMs are often trained simply on text alone, without further grounding and with training objectives focus on predicting missing words, \cite{merrill-etal-2022-entailment} many argue that such probabilistic language modelling tasks cannot in principle lead to the learning of meaning, \cite{bender-koller-2020-climbing} with this cited as a possible reason for some of the mistakes that even SOTA LLMs can be prone to. \newline \par
In this thesis, we seek to bridge this gap and improve the performance and reliability of LLMs by imbuing them with the concept of semantic entailment during their training. We apply highly novel approaches for understanding semantic entailment through Topological Data Analysis (TDA) to study the topology of language, and develop a new metric that can robustly measure entailment, that is grounded theoretically on the concepts of entailment cones in hyperbolic geometric space. Subsequently, we approximate this new entailment metric through a differentiable function that we inject as a regularizer into the training process of an LLM; where an additional optimization goal during training is to maintain high entailment scores. We compare our `entailment-enhanced' LLM against various SOTA-models on core entailment challenges and demonstrate that our method results in an improvement of at least XX\% F1-score compared to the next best model, across all datasets. 


\end{abstract}


\section*{Acknowledgments}
Comment this out if not needed.

\clearpage{\pagestyle{empty}\cleardoublepage}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%--- table of contents
\fancyhead[RE,LO]{\sffamily {Table of Contents}}
\tableofcontents 


\clearpage{\pagestyle{empty}\cleardoublepage}
\pagenumbering{arabic}
\setcounter{page}{1}
\fancyhead[LE,RO]{\slshape \rightmark}
\fancyhead[LO,RE]{}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Introduction}
\section{Motivation of the Thesis}
Language lies at the heart of the upsurge in Artifical Intelligence over the last 10 years. The arrival of Large Language Models (LLMs) who can almost flawlessly reproduce language, discourse on any subject, and answer the most complex of questions with relative assuredness has been transformative across industry and academia alike. Indeed, the prowess with which such LLMs have seemingly mastered language has led, particularly amongst mainstream media, to comparisons with ``god-like'' technology. \cite{hogarthFT} Investigations into the nature of language through the lens of topology, and the ability for LLMs to truly master language, form the core motivation for this thesis, which is discussed in the following section. 


\subsection{What is the meaning of language?}

Whilst this is a Computer Science thesis, the fundamental motivation behind the topic is a similar question that motivated my undergraduate dissertation in Modern and Medieval Languages; namely - what does it mean to \textbf{\textit{truly}} speak a language. \newline \par

I began that dissertation with a quote from Bertolt Brecht during his exile in the United States, that I believe is equally relevant for this thesis:
\begin{quote}
    `I haven't the slightest hope of ever learning colloquial American English. It's certainly not for a lack of trying [...] It's something else that evades me. [...] In discussions, I'm not able to say what I want, just what I can. [...] One could assume that this confusing state would be temporary [...], but that is sadly wishful thinking. It's not that I'm unable to grasp the vocabulary, nor the syntactical or grammatical knowledge. Rather, what I cannot grasp is a certain linguistic \textit{Habitus}, which I simply do not see any possibility of learning.' \cite{brecht} (p. 44)
\end{quote}

Brecht's experience of fluency of alienation from the linguistic \textit{habitus} of a foreign language, no matter how fluently it is spoken, is one that would resonate with any linguist. Yet, we ask and, indeed, expect LLMs to inhabit the linguistic \textit{habitus} of all languages at the same time with expert accuracy. \newline \par

In addition to an expectation of fluency and familiarity with our language, we also expect LLMs to understand and answer our questions in the same reasonable and reliable manner as we would expect from a subject matter expert. To fulfil these expectations, the ability for LLMs to understand semantic `meaning' and entailment is key. This is, however, not necessarily the case today. The ability of LLMs to produce meaningful and reasonable outputs to questions is thanks to the vast wealth of training data they ingest and conduct missing-word prediction tasks on, that allows them to develop highly sophisticated probability models, rather than having a deeper understanding of semantic meaning itself. \cite{merrill-etal-2022-entailment} \cite{bender-koller-2020-climbing} \newline \par 
While Bender et al. cast doubt on the ability of LLMs to truly understanding meaning, and hence on their ability to robustly evaluate more challenging semantic entailment tasks, it is worth noting the complexity that can accompany such tasks, which humans too can struggle with. For example, given the premise \textit{``All men are created equal''} with contextual knowledge of its origin in the US Declaration of Independence, multiple `valid' interpretations of the hypothesis \textit{``Every person has the same inherent value''} are possible, each with very different ramifications:
\begin{enumerate}[itemsep=0pt]
    \item \textit{Contradiction}: `Men' in 1776 deliberately excluded women, enslaved people, Indigenous peoples.
    \item \textit{Entailment}: Despite historical limitations, the principle of the hypothesis is universal and should be understood as such.
\end{enumerate}

The inherently uncertain, fallible and \textit{individual} nature of language that these examples have attempted to exemplify is one  that has been much studied from a philosophical point of view. Notably, Jacques Derrida \cite{derrida1, derrida2, derrida3} maintains that the meaning of all language, whether speech or writing, is created through unstable, spatial and temporal relations between signifiers, that he terms diff√©rance - with every language-speaker caught up in the matrix of differences through which language functions. \newline \par

A core driver of this thesis then, is to investigate whether - contrary to the philosophical arguments given above - we can use concepts from Topological Data Analysis to find an objective, \textit{universal} mathematical representation of language semantics in which the concept of entailment can be robustly defined, modelled, and imbued into an LLM training regime, in order to improve its performance.


\subsection{The importance of understanding language in the age of Artificial Intelligence}
The questions raised in the previous section are of far greater practical significance than mere intellectual curiosities. Since the advent of LLMs, society has grown rapidly reliant on them - ChatGPT alone is forecast to have 1 billion users, almost 10\% of the world's population, by the end of 2025 at the latest. \cite{forbesChatGPT} \newline \par

Given this trajectory towards dependency on the outputs of LLMs, where such tools are consulted in the making of critical personal, business, or even political decisions, the safety and trustworthiness of their responses is essential. Yet this is precisely where we have the least understanding and control of LLMs. As explained by Fitz et al. (2024) \cite{fitz2024hiddenholestopologicalaspects}, the emergence of certain behaviours in LLMs is still a complete mystery, and very little is understood about the structure of their representation manifolds - i.e., the high-dimensional geometric structures that emerge in the neural network's internal layers that represent the model's internal organisation of information. Many elements of how LLMs function still remain a `black box'. We only interact with them at the level of their textual output, in which their natural topological structures - i.e. the `thoughts' of the system - are lost. \cite{fitz2024hiddenholestopologicalaspects}. For example, Figure 1.1, taken from Fitz (2022), \cite{fitz22a} (p.1) shows a graph projection of vector space embeddings of word tokens from French and English. The differences in shape are striking, but the reasons for these differences are still unclear. \newline

\begin{figure}[tb]
\centering
\includegraphics[width = 1\hsize]{./figures/graph_projection_fitz}
\caption{A graph projection of vector space embeddings of word tokens derived from corpora of French (left) and English (right).}
\label{fig:EmbeddingsFrenchEnglish}
\end{figure}

\par
This thesis hence seeks to conduct further investigations into the topology and geometry of the vector embeddings of language in LLMs. Such investigations are of manifold importance: the more we understand about the topology and geometry of LLMs, the better we can understand why they exhibit certain behaviours, and how we can improve their efficiency and parametrisation to enable smaller, more compressed models \cite{fitz2024hiddenholestopologicalaspects}. \newline \par

We, however, will focus specifically on understanding how relationships of semantic entailment are projected into the vector spaces that allow LLMs to `think'. We aim to develop an entailment metric that, when implemented as a regularizer in LLM training, will lead to better LLM performance on semantic entailment tasks. In doing so, we may also uncover potential answers to some of the more philosophical questions posed in the previous section, relating to what it means to speak a language, for humans and for AI. 

\section{Research Aim And Contributions}

The aim of this project is to understand the topology of language in LLM vector spaces and derive therefrom a robust expression that characterises the notion of semantic entailment, which, when used as a regularizer in LLM training, can improve performance on semantic and visual entailment tasks.  \newline \par

To achieve this aim, we make the following contributions: 

\begin{enumerate}[itemsep=0pt]
    \item \textbf{We implement Topological Data Aanalysis (persistent homology, MAPPER) to investigate topological relationships between entailed, contradictory, and neutral premise-hypothesis pairs.} In Chapter X, we undertake this for semantic entailment, using the Stanford Natural Language Inference (SNLI) dataset. In Chapter (X+1), we replicate this task for a visual entailment dataset (SNLI-VE), where premises are given in the form of images rather than phrases.
    \item \textbf{We develop a robust mathematical expression for entailment within topological space, using hyperbolic entailment cones}, from which we derive an entailment metric that can produce accurate entailment scores across semantic and visual entailment challenges; and be used to compare existing LLM performances on such tasks
    \item \textbf{We train an LLM with an `entailment regularizer'}, based on an approximation of the entailment expression in 2., and demonstrate that it has superior performance on semantic and visual entailment tasks vs. SOTA benchmarks 
    \item \textbf{We reason briefly on the philosophical and linguistic implications of our findings}, including what our findings imply about AI's ability to \textbf{\textit{truly}} understand language and meaning. 
\end{enumerate}


\section{Report Structure}
Chapter 2 provides an overview of the relevant theoretical and practical background to this work. This includes an outline of the logic and theory underpinning questions of entailment (Section 2.1), and a summary of existing approaches to both semantic and visual entailment within the fields of NLP and computer vision, respectively (Section 2.2). We provide a brief grounding in key concepts from Topological Data Analysis (TDA) for the unfamiliar reader (Section 2.3), and highlight the handful of existing applications of TDA to language, upon which this thesis builds. \par   \quad In Chapter 3, we develop the core theoretical element of this thesis, introducing the topological mapping of premise-hypothesis pairs, and the development of a metric to measure semantic entailment. \par 
\quad Chapter 4 presents experimental results displaying the robustness of the entailment metric across both semantic and visual entailment datasets, and evaluates the performance of SOTA LLMs to detect entailment against our metric. \par
\quad Chapter 5 outlines the approach taken to approximate our expression for entailment into a differentiable function that we implement as a regularizer in the training of an LLM, and demonstrates, through experiments, its superior performance against both SOTA LLMs, and other benchmark methods used in entailment challenges. \par
\quad Finally, Chapter 6 summarizes the contributions of this thesis, discusses potential avenues for future work suggested by our findings, and attempts to provide an answer to some of the more philosophical and linguistic questions raised by this research before concluding the thesis.




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Background and Related Work}
This chapter presents an overview of key related works in the fields of semantic and visual entailment, before providing a minimum grounding in the primary Topological Data Analysis (TDA) methodologies that will be used throughout this thesis. \newline \par

Section 2.1 focuses on logical investigations into semantic entailment, which theoretically underpin how we practically apply topological data analysis (TDA) methods in this thesis. \par \quad Section 2.2 introduces key practical datasets that have been used to experiment with semantic and visual entailment challenges in the NLP and Computer Vision communities respectively, alongside the various metrics used, and approaches adopted.  \par \quad Finally, section 2.3 introduces two key Topological Data Analysis (TDA) methodologies - Persistent Homology and MAPPER - before surveying existing practical applications of TDA in NLP, and briefly discussing the benefits of Euclidean vs. Hyperbolic Geometry in the context of topological investigations into entailment - a question that is highly relevant for the practical approach we adopt in the following chapters of this thesis. 

\section{Logical Representations of Entailment}

To understand how semantic entailment can be captured through topological methods, it is useful to examine its foundations in formal logic. Semantic entailment is, of course, fundamentally an exercise in logic. Natural language sentences can be broken down into their fundamental logical constituents and evaluated in Conjunctive Normal Form (CNF) through the language of propositional or predicate logic - and indeed this is one of the existing approaches to Semantic Entailment tasks that will be outlined in Section 2.2. As a simple example \cite{fSadri}, take the premises: 
\begin{flushleft}
\text{`If there are national elections, either the Tory party wins or the Labour party wins.'} \\
\text{`If the unions do not support the Labour party then it does not win.'} \\
\text{`There are national elections.'}

\end{flushleft}

\par and the hypothesis:
\begin{flushleft}
If the Tory party does not win then the unions
support the Labour party?    
\end{flushleft}

Using `E' to stand for elections, `L' to stand for a Labour victory, `T' to stand for a Tory victory, and `U' to stand for unions supporting labour, we can easily remodel these natural language statements into CNF: 
\begin{align*}
\text{Premise:} \quad & E \rightarrow L \lor T, \quad \lnot U \rightarrow \lnot L, \quad E \\
\text{Conclusion:} \quad & \lnot T \rightarrow U
\end{align*}

From which we can easily prove that the conclusion is entailed by the premise, since in all cases where $\lnot T$ is true, we can see from the first WFF of the premise that $L$ must be true, and hence from the second that $U$ must also be true. \newline \par

This relationship between semantic entailment and logical entailment is important, because multiple works have derived `idioms' of entailment from logical analysis, which, as we shall now outline, provide  theoretical justification for this thesis' hypothesis that topological features in embedding spaces can capture semantic entailment relationships. 

\subsection{Entailment as a Subsumption Relationship of Hypergraphs}

Jennings et al. \cite{leibnizianAnalysis} formulate a novel approach to entailment, using Leibnizian analysis to prove how logic entailment can be demonstrated through subsumption relationships between hypergraphs. Before discussing their work and its relevance to this thesis, we first outline several key concepts for the unfamiliar reader: 
\begin{itemize}[itemsep=0pt]
    \item \textbf{Possible Worlds}. In logic, a possible world represents one possibility of truth values. For example, if we have a simple logical premise represented by literals $p$ (meaning, say, that it is raining), and $q$ (meaning, say, that the ground is wet), there are four possible worlds:
    \begin{enumerate}[topsep=0pt, itemsep=0pt]
        \item $w_1$: both p and q are true
        \item $w_2$: p is true, q is false
        \item $w_3$: p is false, q is true
        \item $w_4$: both p and q are false
    \end{enumerate}
    \item \textbf{Powersets}. The powerset of possible worlds, denoted by Jennings et al. as $\wp(U)$ \cite{leibnizianAnalysis}, is the set of all possible sets, i.e. representing the universe in a full propositional model. The subset $\{w_1, w_2\}$ within $\wp(U)$ would, in this example, represent all worlds in which ``it is raining'' is true. 
    \item \textbf{Hypergraphs}. Borrowing the defintion directly from Jennings et al. \cite{leibnizianAnalysis} (p.5), `a hypergraph $H$ is a pair $H=(X, E)$ where $X$ is a set of elements, called nodes or vertices, and $E$ is a non-empty set of non-empty subsets of $X$, each of which is called a (hyper-)edge.' 
    \item \textbf{Atomic Constituents}. An atomic constituent is the simplest, irreducible form of a logical expression - i.e., a literal in propositional logic. As such, CNF can be viewed as a disjunction of atoms.
\end{itemize}

With this background, we can summarize the key insights outlined by Jennings et al. \cite{leibnizianAnalysis}, and their relevance for a topological investigation of semantic entailment in this thesis. We refer the interested reader to \cite{leibnizianAnalysis} for the detailed proofs. \newline \par \quad 
1. Since every sentence can be broken down into its conjunctive normal form, every sentence of that language can be represented as a simple hypergraph, $H$, on the powerset of a universe of states'. This is particularly relevant in the context of this thesis' topological approach, since hypergraph representations can embed logical relationships into a geometric form. \newline \par \quad
2. An entailment relationship $\alpha \models \beta$, corresponds to a subsumption relationship between two hypergraphs on $\wp(U)$, such that $H_{\alpha} \sqsubseteq H_{\beta}$. The subsumption relationship captures the idea that every logical requirement of the conclusion must be "underwritten" by some requirement of the premise. The subsumption relationship is defined formally as \cite{leibnizianAnalysis}: 
$$
\forall H, H' \in \mathbb{H},\; H \sqsubseteq H',
\text{ if and only if }
\forall E' \in H',\; \exists E \in H \text{ such that } 
\forall e \in E,\; \exists e' \in E' : e \leq e'  
$$ 

where $\mathbb{H}$ is a set of \textit{simple} hypergraphs such that $\mathbb{H} \subseteq \wp\wp(U)$, and $e \leq e'$ represents a partial ordering on vertices where $e$ corresponds to a logically stronger or more specific condition than $e'$. Figure 2.1 demonstrates a trivial example of this, where a premise $(p \lor q \lor r) \land (\neg s \lor q) $  is modelled by the hypergraph $H_A$, whilst a conclusion $q \lor r$ is modelled by hypergraph $H_B$.

\begin{figure}[H]
\centering
\includegraphics[width = 0.5\hsize]{./figures/HypergraphIntro.drawio.png}
\caption{A hypergraph representation of $(p \lor q \lor r) \land (\neg s \lor q)$ in $H_A$, and $q \lor r$ in $H_B$}
\label{fig:Hypergraphs}
\end{figure}

Following the definition above, for the entailment to hold (i.e., for $H_A \sqsubseteq H_B$), every hyperedge of $H_B$ (in this case just $e_{B1}$), must be `underwritten' by at least one hyperedge in $H_A$. Specifically, for the edge $e_{B1}=\{q,r\}$ in $H_B$, there must exist an edge in $H_A$ such that every vertex in that edge is $\leq$
some vertex in $\{q, r\}$. Since neither $e_{A1}= \{p,q,r\}$ nor $e_{A2}= \{¬¨s,q\}$ satisfies this condition (both contain vertices not logically stronger than elements of $\{q, r\}$), the entailment does not hold. This geometric approach to entailment relationships thus provides a theoretical foundation for investigating semantic entailment through topological methods in this thesis. \newline \par

\quad 3. The definition of entailment relationships via subsumption leads to the emergence of an algebraic lattice structure; namely that $\langle\mathbb{H}, \sqsubseteq\rangle$ is a lattice \cite{leibnizianAnalysis}. Here, the angle bracket notation $\langle\mathbb{H}, \sqsubseteq\rangle$ denotes the mathematical structure consisting of the set $\mathbb{H}$ of simple hypergraphs together with the subsumption relation $\sqsubseteq$ as its partial ordering. The connection between entailment relations and distributive lattices is further developed by Cederquist and Coquand \cite{Cederquist}, who establish a direct bridge between the abstract logical system of entailment relations and topological spaces, through the use of distributive and normal lattices. This lattice structure has the following important tenets:
\begin{enumerate}[itemsep=0pt]
    \item \textbf{Partial Order}: The subsumption relation creates a partial order between the hypergraphs involved. For example, if $H_A \sqsubseteq H_B$, then we can colloquially think of $H_B$ as `higher' in the lattice than $H_A$, where the higher position corresponds to greater generality or logical weakness.
    \item \textbf{Lattice Operations}: Given any two hypergraphs $H_A$ and $H_B$, we can state that their \textit{join} $(H_A \lor H_B)$ is the hypergraph representing the weakest formula that \textbf{both entail}; whilst their \textit{meet} $(H_A \land H_B)$ is the hypergraph representing the strongest formula that \textbf{entails both}
    \item \textbf{De-Morgan Structure For Negation}: Logical negation can be accomplished using the blocker function $\tau$, which allows the following logical rules to hold true:
    \begin{itemize}[topsep=0pt]
        \item $\tau(\tau(H_A)) = H_A$, i.e. double negation
        \item $H_A \sqsubseteq H_B \iff \tau(H_B) \sqsubseteq \tau(H_A)$, i.e. order reversal under negation
    \end{itemize}
\end{enumerate}

These findings are key for several reasons. Firstly, the hypergraph framework, as noted by \cite{leibnizianAnalysis}, is capable of representing logical entailments of arbitrary complexity - i.e. regardless of how complex the logical premise-hypothesis pair become, they can be captured and organized on the hypergraph-lattice. Secondly, lattices themselves provide a bridge from discrete logical topographic structures (i.e. hypergraphs), to a continuous geometric space, where notions of `height' (how general vs. how specific a formula is), `distance' (how many steps in the lattice separate two formulae), and `directions' (moving up the lattice, as generalization, and moving down, as specialization) are all present. Combined, these two principles lay the theoretical foundation for this thesis' hypothesis that relationships of semantic entailment should be able to be detected and measured through topological analysis. The lattice structure should, in theory, enable the logical relationships of entailment to be preserved when we move from semantics in words and phrases across to their vector space embeddings in LLMs; while the partial order features of lattices capture the asymmetry of entailment, where $A \rightarrow B \neq B \rightarrow A$. \newline \par

The key insight from this brief theoretical overview of entailment is that entailment creates asymmetric, hierarchical structures - whether represented as:
\begin{itemize}[itemsep=0pt]
    \item Subsumption in hypergraphs (logical domain), as shown in \cite{leibnizianAnalysis}
    \item Partial orders in lattices (algebraic domain), demonstrated in \cite{Cederquist} and \cite{leibnizianAnalysis}
    \item Directional relationships in embeddings spaces (geometric domain), shown in Section 2.3
\end{itemize}


The topological approach this thesis takes aims to bridge these representations, drawing on the logical frameworks outlined above, while operating in the continuous, high-dimensional space of semantic embeddings in LLMs.


\subsection{From Logical to Semantic Entailment}

While logical entailment operates on formal symbols with fixed meaning, textual entailment in natural language - incorporating lexis and syntax - must grapple with the often ambiguous and context-dependent nature of language. Some interesting work has already been undertaken studying the ability of neural networks and LLMs to tackle tasks involving logical entailment and textual entailment in natural language. \newline \par

From a logical entailment perspective, Evans et al. \cite{Evans2018} developed a new neural network architecture termed a `PossibleWorldNet', that was able to achieve 96\% accuracy on tasks involving entailment in propositional logic. Such high performance suggested that the network was able to learn the structural patterns of entailment, given that, for propositional logic, determining whether an entailment holds is essentially a question of analysing the structure and sequence of arbitarily named variables, and the inference rules governing the connectives that join them. \cite{Evans2018} \newline \par

The `PossibleWorldNet' architecture was designed with this in mind. It is a variant of a TreeNet architecture that evaluates pairs of propositional logic formulae in different `possible worlds'. In other words, to evaluate whether $A \models B$, the PossibleWorldNet generates a set of possible `worlds', and evaluates A and B in each of them, in a technique Evans et al. describe as a `convolution over possible worlds'. \cite{Evans2018} (p. 1) This architecture significantly outperformed more conventional architectures, such as transformers (by 40-50\%), and convolutional networks (by 40\%). The authors suggest that the poor performance of these traditional models is likely due to their inability to capture with sufficient precision the correct hierarchical structures that exist within logical expression. \newline \par

While these findings are strictly in the field of logical entailment, they have an important implication for the textual entailment tasks we shall explore in this thesis. Current neural models, including the transformer architecture that most LLMs are built on, can often fail to understand the structure of sentences they are meant to evaluate. For example, Bowman et al. \cite{bowman2015} demonstrate how all neural models they tested wrongly classified the premise ``\textit{A man wearing padded arm protection is being bitten by a German shepherd dog}'' and conclusion ``\textit{A man bit a dog}'' as an entailment relationship, instead of as a contradiction. Given this, Evans et al. \cite{Evans2018} emphasise the importance of enabling models to isolate the purely structural sub-problems involved in questions of entailment, and claim that only networks that are able to do so, and that can reliably predict entailment in a formal setting, such as propositional  logic, will be able to reliably evaluate entailment in natural language. This further reinforces the importance of ensuring the entailment metric that we develop and input as a regularizer into LLM training is built on the strong theoretical foundations of first-order logic, such as is enabled by the lattice-based idiom of entailment explored in the previous section. \newline \par

Progressing from logical entailment to focus on natural language semantics, recent work by Merrill et al. \cite{merrill-etal-2022-entailment} explores whether LLMs could in principle learn \textit{meaning} and entailment semantics from being trained purely on text as they are today. They demonstrate that under highly specific conditions - namely when LLMs are trained on data generated solely by Gricean speakers who are uniformly truthful and, when speaking, solely balance two competing objectives: (a) conveying information to their listener and (b) brevity - then entailment relationships can, with some caveats, be detected from this `ideal' language model's probability distributions. \newline \par

However, these conditions are often not representative of the average human speakers, and certainly not representative of the vast wealth of text that is available on the internet and that LLMs are trained on. It is hence no surprise, that the performance of LLMs, and of AI approaches in general, on tasks involving recognising textual entailment (RTE) leaves room for improvement. Indeed, in the survey of textual entailment based question answering methods, Paramasivam and Nirmala highlight that benchmark accuracy scores are often no higher than 50-70\%, particularly for generalised datasets with non-obvious hypothesis-premise entailment pairs that span across multiple domains \cite{PARAMASIVAM20229644}. 

\section{Progress, Approaches, and Benchmarks in Semantic and Visual Entailment}

\subsection{Recgonizing Textual Entailment (RTE)}

Recognizing Textual Entailment (RTE) and Natural Language Inference (NLI) are two common names given to evaluation frameworks that aim to assess and measure the semantic understanding of different NLP systems, \cite{poliak-2020-survey} through testing their ability to determine if one sentence can be inferred from another. The definition of entailment used in RTE and NLI is more lenient than strict definition used in linguistics/logic where sentence A only entails sentence B if, in all models in which A is true, also B is true. \cite{sep-montague-semantics} This difference is highlighted in the annotation guidelines of the 2005 PASCAL RTE dataset released by Dagan et al, in which is stated that, for the purposes of RTE, entailment means that a hypothesis must be in principle entailed by the text. Namely, a hypothesis would be judged as false if it includes parts that cannot be inferred from the text, but in cases in which inference is very probable, but perhaps not completely certain, it is still judged as true. \cite{dagan2005} \newline \par

This is an important distinction. The more lenient notion of entailment in RTE and NLI is indicative of the purpose of the such tasks - namely to evaluate the semantic understanding of NLP systems, which are built with specific objectives - be it as an LLM, a machine translator, an information retrieval system or otherwise. In virtually all these cases, where inference is very probable, it is beneficial for the system to evaluate the premise-hypothesis pair as entailed, (e.g. resulting in it retrieving the likely relevant information in the case where it is an IR system), rather than as contradictory. In a similar vein, we want NLP systems to be able to deal with cases of `near-contradiction' in NLP problems, such as in the example pair of sentences: $x$ = I‚Äôm not in North America, and $y$ = I‚Äôm in a US state \cite{merrill-etal-2022-entailment}. As Merril et al. point out, $y$ is a `near-contradiction' of $x$ as both $x$ and $y$ are only in worlds where the speaker is in Hawaii - hence the importance of NLP systems being able to utilise as much additional context as possible to judge questions of semantic entailment. 

\subsection{An Overview of Key RTE Datasets} 

The following section provides an overview of some of the key datasets that have been used either as training data to improve the ability of NLP systems to evaluate semantic entailment, or as test datasets to assess the abilities of such systems. Some of the datasets discussed below will be leveraged as training and test datasets for the experiments conducted in this thesis [add precisely which when experiments conducted]. \newline \par

\textbf{FraCas}. Developed by Cooper et al. in 1996 \cite{CooperFracas}, \textit{FraCas} is a short dataset of roughly 350 examples of premise-hypothesis pairs, created manually by linguists with the specific aim of testing an NLP systems' ability to understand a range of semantic phenomena including generalized quantifiers, plurals, anaphora, ellipsis, adjectives, comparatives, temporal references, verbs, and attitudes \cite{poliak-2020-survey}. Premises are at least one sentence long, but can be multiple, and hypothesis are written as a question, with possible answers being `\textit{Yes}' for entailment, `\textit{No}' for contradiction, or `\textit{Don't know}' for neutral. While the \textit{FraCas} dataset has the benefit of being crafted to evaluate an NLP systems' performance against specific semantic phenomena, its short size prevents it from being a viable model to train deep learning models on - although it remains useful as a test dataset. \newline \par

\textbf{Pascal RTE Challenges}. The first Pascal RTE challenge, developed by Dagan et al. \cite{dagan2005}, was designed as a generic evaluation framework to assess the inference capabilities of NLP models. \cite{poliak-2020-survey}. It took more of a real-world applied focus than \textit{FraCas}, with premise-hypothesis pairs frequently taken from the downstream tasks of such NLP systems. For example, the first Pascal RTE dataset was composed of premise-hypothesis pairs taken from seven different NLP tasks including, amongst others, document comparison, reading comprehension, question answering, machine translation. \cite{poliak-2020-survey}. Since the first Pascal dataset in 2005, there have been eight further iterations, the most recent being Dzikovska et al. in 2013 \cite{dzikovska-etal-2013-semeval}. Examples of premise-hypothesis pairs from the first three Pascal iterations can be found in Figure 2.2, taken from Poliak (p.5) \cite{poliak-2020-survey}. While the Pascal datasets are significantly larger than the \textit{FraCas} equivalents, they are still not of the size required to train deep learning models on - the first Pascal dataset, for instance, only contains roughly 1000 examples. This brings us onto the more recent, popular and larger RTE datasets that have largely been developed in order to train deep learning models.

\begin{figure}[H]
\centering
\includegraphics[width = 0.8\hsize]{./figures/PASCAL_examples.png}
\caption{Examples from the PASCAL RTE datasets. The first, second and third lines are from PASCAL RTE1, RTE2, and RTE3 datasets respectively}
\label{fig:PASCAL}
\end{figure}

\textbf{Deep Learning Datasets}. We briefly survey four key datasets that are large enough to be used as training datasets for deep learning models. The first of the four, \textit{Sentences Involving Compositional Knowledge} (SICK) was created in 2014 \cite{marelli-etal-2014-sick}, and contains roughly 10,000 examples that can be used to test both semantic entailment (via the typical entailment, contradiction, and neutral labels) and semantic similarity (via a 5 point scale rating) \cite{PARAMASIVAM20229644}. A year later, Bowman et al. \cite{bowman2015} created the \textit{Stanford Natural Language Inference} (SNLI) corpus containing over 570,000 examples. In the SNLI corpus, the same premise can be paired with up to three different hypotheses, each with a potentially different entailment label, as displayed in Figure 2.3 below, taken from Poliak (p.6)\cite{poliak-2020-survey}.

\begin{figure}[H]
\centering
\includegraphics[width = 0.8\hsize]{./figures/SNLI_examples.png}
\caption{Examples from the development sets of SNLI (top) and MultiNLI (bottom)}
\label{fig:SNLI}
\end{figure}

The \textit{Multi-Genre Natural Language Inference} (MNLI) dataset was introduced in 2018 by Williams et. al \cite{williams-etal-2018-broad}, to build on the SNLI dataset by collecting roughly 430,000 examples across ten different written and spoken languages, as opposed to SNLI where all examples are in English. The final dataset worth mentioning is the \textit{SciTail} dataset developed by Khot et al. \cite{Khot_Sabharwal_Clark_2018}, which differs from the three previously mentioned datasets, insofar as it is the only one of the four to have been created from existing textual sources, rather than through crowd-sourced workers and volunteers. The SciTail dataset is, however, a lot smaller than SNLI and MNLI, containing just under 30,000 examples of science-themed premise-hypothesis pairs. \newline \par

\subsection{Common approaches to semantic entailment tasks}

This section outlines the core approaches that have thus far been adopted to tackle textual entailment challenges, and highlights certain shortcomings and limitations of each approach. \newline \par

Following Paramasivam and Nirmala \cite{PARAMASIVAM20229644}, we categorise approaches to RTE as typically falling into one or several of the following categories:
\begin{itemize}[itemsep=0pt]
    \item \textbf{Lexical approaches}, that focus on the linguistic information of input surface strings, without considering syntactic or semantic properties
    \item \textbf{Semantic approaches}, which consider the meaning of the text in broader context to evaluate entailment, as opposed to only considering the input surface strings as in the lexical approach
    \item \textbf{Logical approaches}, where a logical representation language is used to determine entailment
    \item \textbf{AI approaches}, where entailment models are built to recognize entailment, with classifiers used to determine if a text-hypothesis pair of inputs results in entailment 
\end{itemize}

The shortcomings of solely \textbf{lexical} or \textbf{semantic} approaches are evident, since to understand meaning in any language, an understanding of both the lexis and syntax of the language is essential. Moreover, without an understanding of the broader context of the subject matter being discussed, lexical and syntactical understanding even together are still often not enough. Hence, a successful approach would need to focus on both lexical and semantic elements; but major limitations still surround most approaches of this ilk. Taking Shajalal et al's \cite{shajalal} approach as an example of this genre of RTE approaches, in which they propose a methodology that converts into vector representation both lexical and semantic features of words, before using an average of the element-wise Manhattan distance vector (EMDV), Bag-of-Words based (BoW) similarity score, Jaccard similarity score (JAC), and the BERT-based semantic textual similarity score to determine entailment. The problem with this and similar lexical and/or semantic approaches is that they are measuring \textit{semantic similarity} to recognize \textit{semantic entailment}, when in reality, the two are not equal. Take for example of the pair of sentences: \textbf{Sentence A:} ``The cat is sleeping on the sofa'', \textbf{Sentence B:} ``The dog is sleeping on the sofa''. \newline \par


Both these sentences would result in high Bag-of-Words and Jaccard similarity scores, due to the fact that they share every word except for cat and dog. Similarly, in most vector embeddings, `cat' and `dog' are close neighbours from a distance perspective, due to their close semantic relatedness and distributional similarity in training data. In the above sentences, they also play the same grammatical role as the subject of the sentence. Given this trivial example, we can already see how methods that rely on semantic similarity to measure entailment might falsely detect entailment where there is none (as could be the case in the above situation), and vice-versa. Semantic similarity-based methods to entailment  also struggle take into account the asymmetrical and hierarchical nature of entailment. This is again easily demonstrated by means of example:
\begin{flushleft}
    \textbf{Pair A:} \textit{Premise}: `All cats are animals'. \textit{Hypothesis}: `Some cats are animals' \\
    \textbf{Pair B:} \textit{Premise}: `Some cats are animals'. \textit{Hypothesis}: `All cats are animals'
\end{flushleft}

As the premise and hypothesis in both pairs are identical, a distance-based approach that uses semantic similarity to entailment would likely fail to differentiate between the fact that \textit{Pair A} is an entailment relationship, while \textit{Pair B} is not an entailment relationship, due to the difference in directional relationships between the pairs. \newline \par

\textbf{Logical approaches} to entailment, such as the one discussed in Section 2.1.2 are able to resolve some of these difficulties thanks to their ability to focus on the structure and hierarchical relationships of arbitrarily-named variables; rather than having to deal with lexical and syntactical parsing of natural language. However, they are of less use for the purposes of this thesis, which focuses on developing a metric for semantic entailment that can be used to measure and improve the performance of LLMs, and must hence be grounded in natural language, where words can be replaced by synonyms, and word order and syntax can be restructured without changing meaning. \newline \par

The category of \textbf{AI approaches} described by Paramasivam and Nirmala \cite{PARAMASIVAM20229644} is mostly used to designate deep learning entailment models that may focus to greater or lesser on lexical, semantic or logical elements of sentences depending on the model. As Poliak notes \cite{poliak-2020-survey}, the recent advances in deep learning have led to a resurgence of interest in RTE challenges and one needs to only look at the SNLI leaderboard to see the high accuracy scores that have been achieved with such AI approaches (the current leading benchmark having achieved 94.7\% accuracy). \newline \par

Despite such high accuracy scores, these AI approaches also suffer from important shortcomings. As Poliak points out \cite{poliak-2020-survey}, the resurgence of interest in RTE caused by the advent of deep learning did not focus on how such methods could improve our understanding of semantic entailment to improve the field of NLP more broadly, but rather was driven primarily by researchers competing with one another to achieve the top score on leaderboards for new RTE datasets, in a manner that was isolated from real-world use cases. Going further than this, both Pavlick \cite{pavlick2017} and White et al. \cite{white-etal-2017-inference} argue that the high scores achieved in some of these leaderboards actually provide little evidence to suggest that such models are able to capture the type of compositional or world knowledge tested by datasets like FraCas, which were deliberately crafted in a manner to challenge the ability of NLP systems to cope with a range of semantic phenomena. Nor do they shed light on the types of linguistic properties that are better understood by high-performing entailment models. Put differently, while the accuracy metric used to measure RTE may indicate how well that model determines if one sentence entails another, it certainly does not yet explain which semantic phenomena are important for understanding semantic entailment \cite{poliak-2020-survey}. Through our topological approach to semantic entailment, we hope to both improve entailment accuracy on more challenging RTE datasets, and to be able to clearly define the topological features that can be used to robustly determine entailment. \newline \par

Further evidence of the shortcomings of high-scoring AI approaches, and the lack of their actual understanding of deeper semantic meaning is provided by Sanwal \cite{sanwal2024evaluatinglargelanguagemodels}, who showed how an LLM-based model that achieved 89.9\% accuracy on the SNLI dataset experienced a significant performance drop of 17\%, to only achieve 72.5\% accuracy when tested on a `contrast set'. Sanwal suggests that this drop in performance was likely due to limitations of the SNLI dataset which lacks the nuanced and diverse examples that were integrated into the contrast set, and were deliberately created to expose the model to a broader range of linguistic scenarios. This casts doubt on the ability of high-performing entailment models to generalize well to other entailment datasets. \newline \par

In summary, material shortcomings exist with every major category of approach to RTE tasks. While more recently `AI approaches' have yielded high accuracy scores on key datasets such as SNLI, their ability to generalise away from the often simple examples of these datasets is under scrutiny. By developing a metric for semantic entailment that is built upon solid logical and theoretical foundations, and that is demonstrable through topological data analysis, we seek to address some of these shortcomings.

\subsection{Visual Entailment}

Alongside semantic entailment sits the related task of visual entailment. Instead of a textual premise-hypothesis pair, in visual entailment tasks the premise is an image, while hypotheses remain textual sentences that models are to classify with \textit{entailment}, \textit{contradiction}, or \textit{neutral} labels. \newline \par

The key visual entailment dataset, \textit{SNLI-VE}, was developed by Xie et al.\cite{xie2019visualentailmentnoveltask} and is built on the SNLI dataset discussed above. Figure 2.2, taken from Xie et al. (p. 2) \cite{xie2019visualentailmentnoveltask} provides an example of the premise-hypothesis pairs from SNLI-VE. 

\begin{figure}[H]
\centering
\includegraphics[width = 0.5\hsize]{./figures/SNLI-VE.png}
\caption{An Example from SNLI-VE dataset}
\label{fig:SNLI-VE}
\end{figure}

In the same paper, Xie et al. propose both transformer and CNN-based architectures as viable solutions to tackle the visual entailment challenge, achieving benchmark accuracy scores of just over 70\%.

The visual entailment task is of relevance to this thesis because we hypothesise that the topological entailment relationship we seek to define between textual premise-hypothesis pairs in a high-dimensional embedding space could also hold for multimodal premise-hypothesis pairs, where an image serves as the premise and text as the hypothesis. This would require mapping both visual and textual representations into a shared embedding space, enabling the hyperbolic entailment cone framework, that we seek to develop to describe entailment relationships, to operate across modalities.

\section{Topology of Language}

\subsection{Topological Data Analysis (TDA)}

Topological Data Analysis (TDA) applies concepts from topology - a branch of mathematics - in the fields of computer and data science, based on the observation that data points have implicit shapes. \cite{savle-etal-2019-topological} Due to the fact that the `shape' of texts are not instantly obvious, TDA has not been explored as much in the field of NLP as it has been in certain other domains such as Computer Vision \cite{uchendu2024unveilingtopologicalstructurestext}. Despite this, texts can indeed take the shape of their numerical representations, but different numerical representations of text capture different linguistic features. Hence, the choice of representation matters, whether Term Frequency - Inverse Document Frequency (TF-IDF), Word2Vec, GloVe, or FastText embeddings are used \cite{uchendu2024unveilingtopologicalstructurestext}. There are two principal methods that TDA encompasses, which we shall provide a brief overview of:
\vspace{-10pt}
\subsubsection{Persistent Homology}
Persistent homology is the more popular of the two methods, and uses algebraic topology to extract topological features across different spatial dimensions. \cite{uchendu2024unveilingtopologicalstructurestext} We provide a brief summary of the method below, but direct the interested reader to Uchendu and Le \cite{uchendu2024unveilingtopologicalstructurestext} for a more thorough explanation of the concepts underlying persistent homology. \newline \par 

In persistent homology, data is represented as a point cloud in high-dimensional space, with the aim of systematically analysing how topological structures emerge and disappear as the data is examined at different resolutions. To achieve this, the Persistent Homology algorithm uses Vietoris-Rips complexes, which can be thought of as drawing circles of increasing radius around each data point in the point cloud. As the circles grow, they eventually touch and overlap, forming multi-dimensional simplicial complexes. During this process, topological features - characterised by their dimension - naturally appear and disappear. For example, connected components represent 0-dimensional holes ($\beta_0$), loops or tunnels represent 1-dimensional holes ($\beta_1$), and voids represent 2-dimensional holes ($\beta_2$) The algorithm carefully tracks when each feature is `born' (first appears) and when it `dies' (disappears due to merging or filling), which is important since features which have long `lifespans' represent robust structural properties of the data, while short-lived features are typically noise. An example of the Persistent Homology methodology and how it can be visualised is shown in Figure 2.3 taken from Huang et al. (p.2)

\begin{figure}[H]
\centering
\includegraphics[height = 0.2\textheight]{./figures/PHomology.png}
\caption{$H_0$ and $H_1$ capture the number of connected components and number of holes at different resolutions}
\label{fig:PersistentHomology}
\end{figure}

\subsubsection{Mapper}

The other main tool commonly used in TDA feature extraction is \textit{Mapper}, proposed by Singh et al. \cite{singh2007} to visualize topological structures in data. Once again, we refer the interested reader to Uchendu and Le \cite{uchendu2024unveilingtopologicalstructurestext} for a more detailed explanation of the methodology, which we only briefly summarize here. \newline \par

Mapper works by creating simplified graph representations of high-dimensional data through a combination of dimension reduction and clustering techniques. As such, it focuses on analysing and visualising the overall shape and connectivity structure of data, rather than tracking features of high dimensional data across different scales, as persistent homology does. The Mapper algorithm follows four main steps: 
\begin{enumerate}[itemsep=0pt]
    \item High-dimensional data is projected into a lower-dimensional space using any robust dimension reduction technique, such as Principal Component Analysis (PCA).
    \item A cover is created of the projected space, using overlapping intervals of constant length.
    \item For each interval in this cover, Mapper examines the corresponding pre-image - i.e. the original high-dimensional points projecting into that interval - and applies a clustering algorithm to group nearby points in each interval. This ensures that the clusters represent meaningful local neighbourhoods in the high-dimensional original space, preventing data points that were originally far apart from each other, but that were projected into the same lower dimensional interval, from ending up in the same cluster.
    \item A graph is constructed where each vertex represents a cluster, and edges connect vertices whose corresponding clusters share common data points. In this way, the graph represents the connectivity structure of the original data and shows how different regions of the data relate to each other. 
\end{enumerate}   

\subsection{TDA applied to Language}

The application of TDA methodologies to language remains a relatively niche aspect within the broader field of NLP. Indeed, in the survey of TDA applications to NLP conducted by Uchendu and Le \cite{uchendu2024unveilingtopologicalstructurestext}, they could find no more than 87 relevant papers; most of which are very recent. Despite the limited exploration to date, some particularly interesting results have already been demonstrated. We overview a small sample of these to give the reader an understanding of what has been achieved already through the application of TDA to language. They can be divided into three broad categories. \newline \par

\textbf{TDA for analysis of linguistic similarity}. One of the key use cases of TDA in the domain of language has been to detect the similarity and differences between various linguistic inputs. On a more global scale, this includes work such as Port et al's analysis of the syntactic topology of different languages to investigate relatedness between, and the development of, language families (e.g. Indo-European, Niger-Congo, etc.) \cite{port2018, port2022}. On `smaller' scale, Zhu \cite{zhu2013} was able to demonstrate how the topological analysis of linguistic features in text allowed for reliable differentiation between the writing style's of children, adolescents, and adults - based on their linguistic similarity. \newline \par

\textbf{TDA for Text Classification}. The ability to exploit TDA to analyse linguistic similarity gave rise to a myriad of further applications where features extracted from TDA could help in text classification for various purposes, including:
\begin{itemize}[itemsep=0pt]
    \item Robust detection of AI-generated/deepfake text detection \cite{uchendu2024topformertopologyawareauthorshipattribution, tulchinskii2023intrinsicdimensionestimationrobust, kushnareva2024aigeneratedtextboundarydetection}, and of fraudulent academic papers \cite{tymochko2021}
    \item Grammatical acceptability classification \cite{cherniavskii-etal-2022-acceptability}
    \item Text genre classification, e.g. of movie plots \cite{doshi2018}, and authorship attribution, e.g. of Persian poems \cite{elyasi2019introductionnewtextclassification}
\end{itemize}

\textbf{TDA for Semantic Meaning}. This is the most relevant category of existing TDA applications for the purposes of this thesis, and includes studies that have explored:
\begin{itemize} [itemsep=0pt]
    \item The representation and visualisation of semantic space as simplicial complexes in topological space \cite{CHIANG2007256, karlgren2014}
    \item Deriving consistent correlations between sentence vectors and the semantic meaning of a sentence across multiple embedding methods including GPT-3, Word2Vec, and Sentence-BERT \cite{sun2023topologicalinterpretationsgpt3}
    \item Detection of polysemous words \cite{jakubowski-etal-2020-topology} and homonyms \cite{temƒçinas2018localhomologywordembeddings} through the topology of their manifolds 
\end{itemize} 

A final highly relevant paper is Savle et al's \cite{savle-etal-2019-topological} research on applying TDA to discourse structures in order to improve performance on natural language inference tasks in the Competition of Legal Information Extraction and Entailment (COLIEE) dataset. The COLIEE task was to identify whether each of the 181 `base cases' provided from a collection of Canadian legal decisions were entailed or not by the supporting paragraph files that accompanied them. In total, the dataset provided 181 base cases for training, with 8794 accompanying paragraph files. 239 of these paragraph files positively entailed at least one of the 181 base cases, while the remainder did not. This led to a highly unbalanced training set which, combined with the highly specialized legal subject matter, resulted in challenges for traditional neural network or semantic similarity approaches to the problem \cite{savle-etal-2019-topological}. Interestingly, Savle et al. demonstrated how, when the textual inputs were analysed via persistent homology, the radius of birth-death cycles significantly differed between entailed documents and non-entailed documents, \cite{savle-etal-2019-topological} enabling them to improve on the F-score of the previous highest-performing COLIEE model by over 5\%. This thesis aims to build on the work outlined by Savle et al., and suggest answers to what they term as the ``tension between the positive empirical results deriving using topological methods and our lack of understanding why these methods work.'' (p. 2)\cite{savle-etal-2019-topological}

\subsection{Topological Structures of Entailment: Hyperbolic Geometry and Entailment Cones}
Recent advances in geometric approaches to semantic relationships can provide inspiration for how we shall look to identify entailment relationships in the topological spaces created through TDA. Of particular interest is the concept of entailment cones, developed by Dhall et al. \cite{dhall2020hierarchicalimageclassificationusing} and Ganea et al. \cite{ganea2018hyperbolicentailmentconeslearning}, which describe geometric structures that naturally encode the asymmetric and hierarchical nature of logical entailment. \newline \par

The concept of entailment cones is reliant on the notion of \textit{order-embeddings}, as set out by Vendrov et al. \cite{vendrov2016orderembeddingsimageslanguage}, which bridge the gap between standard word vector representations and the hierarchical nature of semantic relationships, by modelling the partial order structure of such hierarchies in the embeddings. As Dhall et al. \cite{dhall2020hierarchicalimageclassificationusing} points out, this approach directly addresses entailment's inherent directionality by creating an `asymmetric distance resulting in the formation of a transitive embedding space' (p.3), as displayed in Figure 2.4 borrowed from Dhall et al. (p.3).  

\begin{figure}[H]
\centering
\includegraphics[height = 0.2\textheight]{./figures/OEandEC.png}
\caption{Comparing embedding space for order-embeddings and entailment cones}
\label{fig:OE+EC}
\end{figure}

The limitation with order-embeddings, as pointed out by Ganea et al. \cite{ganea2018hyperbolicentailmentconeslearning}, is the significant capacity limitations that accompany the orthant-structure, since the capacity of order embeddings grows linearly with the embedding space dimension. Furthermore, they note a further issue with orthant regions; namely that they suffer from large intersections (as shown in the Figure 2.6), which implies that their disjoint volumes rapidly become bounded \cite{ganea2018hyperbolicentailmentconeslearning}. As a solution to this Ganea et al. propose entailment cones as a natural generalization of order embeddings, which replace the rigid orthants with geodesically convex cones that preserve the asymmetric nature of entailment, while providing greater representational flexibility than orthant-based methods. \cite{ganea2018hyperbolicentailmentconeslearning} Furthermore, Ganea et al. demonstrate that entailment cones have significant advantages when implemented in hyperbolic space, as `the volume of any ball grows exponentially with its radius, instead of polynomially as in the Euclidean space' (p. 2) \cite{ganea2018hyperbolicentailmentconeslearning}. This property enables hyperbolic spaces to accommodate the exponential branching structure that is inherent in semantic hierarchies, and that, we hypothesise, will be necessary in robustly modelling semantic entailment. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Project Plan}
Note: Chapter for Background Interim Report only for second marker feedback. \newline \newline
\textbf{Aim to have completed by the end of July:}
\begin{enumerate}[itemsep=0pt]
    \item Using the SNLI dataset, experiment with different topological data analysis methods (e.g. persistent homology, mapper) using a variety of different contextualized word/sub-word embeddings (e.g. TF-IDF, Word2Vec, GloVe, FastText, WordPiece), to investigate whether a reliable entailment score/metric can be produced
    \begin{itemize} [topsep=0pt, itemsep=0pt]
        \item I.e., test the assumption that, if a hypothesis is semantically entailed by a given premise (whether visual or textual), there should be a topological connection (e.g a hyperbolic entailment cone) between the two statements in some higher dimensional space after mapping them using various TDA methods
        \item Aim to find a robust entailment metric that would allow us to match the correct hypothesis with the premise that entails it, after randomization and shuffling of all premises and hypotheses in a given dataset. 
        \item Such a dataset should contain hypotheses that are both entailed, neutral, and contradicted by the premises, so that the final matching will only assign a subset of the hypotheses as entailed by premises, with the rest assigned to either neutral or contradictory labels.
        \begin{enumerate}[topsep=0pt, itemsep=0pt]
            \item Train order embeddings on the SNLI dataset
            \item Convert order embeddings to hyperbolic entailment cones using Ganea et al's closed-form expressions
            \item Apply persistent homology techniques to analyse cone intersection patterns and violation structures
            \item Extract topological features that correlate with entailment strength
            \item Develop differentiable approximation for LLM regularization
        \end{enumerate}
    \end{itemize}
    \item If successful in finding such an entailment metric, look to:
    \begin{itemize}[topsep=0pt, itemsep=0pt]
        \item Test it in further RTE datasets to ensure its robustness (e.g. FraCas, PASCAL)
        \item Extend it create a differentiable function that can be used as a regularizer in LLM training ‚Äì this function in essence being a means of measuring semantic entailment for the LLM
    \end{itemize} 
    \item Train an LLM using this regularizer, and compare its performance to other SOTA/benchmark models across key semantic entailment and visual entailment datasets
\end{enumerate}
\textbf{For August and beyond:}
\begin{itemize} [itemsep=0pt]
    \item Write up results in dissertation
\end{itemize}
 




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Approach, 
Experimental Setup and Method}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Experimental Results and Discussion}
The results are very interesting in Jones 2019.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Conclusion}


%% bibliography
\bibliographystyle{unsrt}
\bibliography{References}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter*{Declarations}




\end{document}