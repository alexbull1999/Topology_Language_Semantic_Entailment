\documentclass[12pt,twoside]{report}

% some definitions for the title page
\newcommand{\reporttitle}{asdfasdf}
\newcommand{\reportauthor}{Your name}
\newcommand{\supervisor}{Name of supervisor}
\newcommand{\reporttype}{Type of Report/Thesis}
\newcommand{\degreetype}{Type of degree} 

% load some definitions and default packages
\input{includes}

% load some macros
\input{notation}

% load title page
\begin{document}
\input{titlepage}


% page numbering etc.
\pagenumbering{roman}
\clearpage{\pagestyle{empty}\cleardoublepage}
\setcounter{page}{1}
\pagestyle{fancy}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\vspace*{-\fill}
\begin{abstract}
Semantic entailment, the question of whether a hypothesis $h$, can be inferred from a text $t$, is a core part of the field of Natural Language Processing (NLP), and one that is key to many important tasks including ``QA [question answering], IR [information retrieval], text summarization, machine translation, information extraction, and paraphrasing.'' \cite{PARAMASIVAM20229644} 
\newline \par
Semantic entailment is also a fundamental task for large language models (LLMs), on which many people are beginning to rely on for knowledge on a daily basis, thus becoming an ever more integral part of society. It is evident that for LLMs to provide reliable, robust answers to questions and meet the expectations of users, an ability to accurately understand questions of semantic entailment is crucial. Yet, given the fact that LLMs are often ``trained on text alone, without additional grounding,'' \cite{merrill-etal-2022-entailment} where training objectives focus on predicting missing words, many argue that this ``language modelling task, because it only uses form as training data, cannot in principle lead to learning of meaning.'' \cite{bender-koller-2020-climbing} \newline \par
In this thesis, we seek to bridge this gap and improve the performance and reliability of LLMs through imbuing them with the concept of semantic entailment during their training. We apply highly novel approaches for understanding semantic entailment through Topological Data Analysis (TDA) to study the topology of language, to develop a new metric that can robustly measure entailment, based theoretically on the concepts of entailment cones in hyperbolic geometric space. Subsequently, we mould the new entailment metric into a differentiable function that we inject as a regularizer into the training process of an LLM; where an additional optimization goal during the LLM's training is to maintain high entailment scores. We test compare our `entailment-enhanced' LLM against various SOTA-models on core entailment challenges and demonstrate that our method results in an improvement of at least XX\% F1-score compared to the next best model, across all datasets. 



\end{abstract}


\section*{Acknowledgments}
Comment this out if not needed.

\clearpage{\pagestyle{empty}\cleardoublepage}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%--- table of contents
\fancyhead[RE,LO]{\sffamily {Table of Contents}}
\tableofcontents 


\clearpage{\pagestyle{empty}\cleardoublepage}
\pagenumbering{arabic}
\setcounter{page}{1}
\fancyhead[LE,RO]{\slshape \rightmark}
\fancyhead[LO,RE]{\slshape \leftmark}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Introduction}
\section{Motivation of the Thesis}
Language lies at the heart of the upsurge in Artifical Intelligence over the last 10 years. The arrival of Large Language Models (LLMs) like ChatGPT who can almost flawlessly reproduce language, discourse on any subject, and answer even the most complex of questions with relative assuredness has been transformative across industry and academia alike. Indeed, the prowess with which such LLMs have seemingly mastered language has led, particularly amongst mainstream media, to comparisons with ``god-like'' technology. \cite{hogarthFT} Investigations into the nature of language through the lens of topology, and the ability for LLMs to truly master language, form the core motivation for this thesis, which is discussed in the following section. 


\subsection{What is the meaning of language?}

Whilst this is a Computer Science thesis, and one that we believe will lead to significant novel discoveries that will materially improve the performance of LLMs in semantic entailment tasks, the fundamental motivation behind the topic is the same question that motivated my undergraduate dissertation in Modern and Medieval Languages; namely - what does it mean to \textbf{\textit{truly}} speak a language. \newline \par

I began that dissertation with a quote from Bertolt Brecht during his exile in the United States, that I believe is equally relevant for this thesis:
\begin{quote}
    I haven't the slightest hope of ever learning colloquial American English. It's certainly not for a lack of trying [...] It's something else that evades me. [...] In discussions, I'm not able to say what I want, just what I can. [...] One could assume that this confusing state would be temporary [...], but that is sadly wishful thinking. It's not that I'm unable to grasp the vocabulary, nor the syntactical or grammatical knowledge. Rather, what I cannot grasp is a certain linguistic \textit{Habitus}, which I simply do not see any possibility of learning.\cite{brecht}
\end{quote}

Brecht's experience of fluency of alienation from the linguistic \textit{habitus} of a foreign language, no matter how fluently it is spoken, is one that would resonate with any linguist. Yet, we ask and, indeed, expect LLMs to inhabit the linguistic \textit{habitus} of all languages at the same time with expert accuracy. \newline \par

Beyond an expectation of fluency and familiarity with our language, a core expectation of LLMs is their ability to understand and answer our questions in reasonable and reliable manners. To fulfill these expectations an understanding of `meaning', and hence of semantic entailment is key; but this is a task we humans can often falter with, even with plentiful context. Given the premise ``All humans are created equal'' with contextual knowledge of the origin of the premise arising from the US Declaration of Independence, multiple equally valid interpretations of the hypothesis are possible ``Every person has the same inherent value'':
\begin{enumerate}
    \item \textit{Contradiction}: "Humans" in 1776 excluded women, enslaved people, Indigenous peoples.
    \item \textit{Entailment}: Despite historical limitations, the principle of the hypothesis is universal.
\end{enumerate}

The inherently uncertain, fallible and \textit{individual} nature of language that these examples have attempted to exemplify is one best summarised by Jacques Derrida \cite{derrida1, derrida2, derrida3}, who maintains that the meaning of all language, whether speech or writing, is created through unstable, spatial and temporal relations between signifiers, that he terms diff√©rance - with every language-speaker caught up in the matrix of differences through which language functions. \newline \par

A core driver of this thesis then, is to investigate whether - contrary to the philosophical arguments given above - we can use concepts from the field of Topological Data Analysis to find an objective, \textit{universal} mathematical representation of language in which the concept of entailment can be robustly defined, modelled, and then used to improve LLM performance.


\subsection{The importance of understanding language in the age of Artificial Intelligence}
The questions raised in the previous section are of far greater practical significance than the intellectual curiosities that they may appear to be on the surface. Since the advent of LLMs only a few years ago, society has grown rapidly reliant on them - ChatGPT alone is forecast to have 1 billion users, almost 10\% of the world's population, by the end of 2025 at the latest. \cite{forbesChatGPT} \newline \par

Given this trajectory towards dependency on the outputs of LLMs, where such tools are consulted in the making of critical personal, business, or even political decisions, the safety and trustworthiness of LLM responses provided is of essential importance. Yet this is precisely where we have the least understanding and control of LLMs themselves. As explained by Fitz et al. (2024) \cite{fitz2024hiddenholestopologicalaspects}, ``as of now it is still a mystery why certain behaviours emerge in large language models, and little is understood about the structure of their representation manifolds.'' Many elements of how LLMs function still remain a `black box'. We interact with them at the level of their textual output, in which ``the natural topological structure of [the] language embeddings, which define the ``thoughts'' of the system, is lost'' \cite{fitz2024hiddenholestopologicalaspects}. For example, Figure 1.1, taken from Fitz (2022), \cite{fitz22a} shows a graph projection of vector space embeddings of word tokens from French and English. The differences in shape are striking, but the reasons for these differences are still unclear. \newline

\begin{figure}[tb]
\centering
\includegraphics[width = 1\hsize]{./figures/graph_projection_fitz}
\caption{A graph projection of vector space embeddings of word tokens derived from corpora of French (left) and English (right).}
\label{fig:logo}
\end{figure}

\par
This thesis hence seeks to conduct further investigations into the topology and geometry of the vector embeddings of language in LLMs. Such investigations are of manifold importance: the more we understand about the topology and geometry of LLMs, the better we can understand why they exhibit certain behaviours, and how we can improve their efficiency and parametrisation, potentially enabling smaller, more compressed models \cite{fitz2024hiddenholestopologicalaspects}. \newline \par

We, however, will focus specifically on understanding how relationships of semantic entailment are projected into the vector spaces that allow LLMs to `think'. We aim to develop an entailment metric that, when implemented as a regularizer in LLM training, will lead to better LLM performance on semantic entailment tasks. In doing so, we may also uncover potential answers to some of the more philosophical questions posed in the previous section, relating to what it means to speak a language, for humans and for AI. 

\section{Research Aim And Objectives}

\begin{itemize}
    \item Explore topology of language and mathematical relationships in topological space through which entailment can be determined
    \item Connect dots between domains that have not been heavily explored
    \item Develop a robust mathematical expression for entailment, that can produce reliable and accurate entailment scores 
    \item Translate visual entailment tasks into topological expressions, so that they can also be measured via the entailment metric - enabling a single expression for multi-modal entailment training 
\end{itemize}


\section{Project Contributions}
\begin{itemize}
    \item New entailment metric derived from topological data analysis
    \item Use of entailment metric as a regularizer in LLM training to improve performance on classic entailment datasets
    \item Across semantic and visual entailment, enabling multi-modal entailment
\end{itemize}
\section{Report Structure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Background and Literature Review}
Introduction / Explanation of the section.
\section{Semantic Entailment}
\textbf{subsections as necessary, e.g. for different types}
\\
\\
Common approaches developed to solve challenges related to semantic entailment, such as those posed in the PASCAL \cite{dagan2006} or Stanford Natural Language Inference (SNLI) \cite{bowman2015} datasets, typically fall into one or several of the following categories \cite{PARAMASIVAM20229644}:
\begin{itemize}
    \item Lexical approaches, that focus on the linguistic information of input surface strings, without considering syntactic or semantic properties
    \item Semantic approaches, which consider the meaning of the text in broader context to evaluate entailment, as opposed to only considering the input surface strings as in the lexical approach
    \item Logical approaches, where a logical representation language is used to determine entailment
    \item AI approaches, where entailment models are built to recognize entailment, with classifiers used to determine if a text-hypothesis pair of inputs results in entailment 
\end{itemize}


\section{Visual Entailment}
\section{Topology of Language}
Theoretical approaches followed by  practical?
\subsection{Fractal Geometry}
\subsection{Persistent Homology}
\subsection{MAPPER}
\subsection{Intrinsic Dimensionality}
\subsection{Sheaf Theory}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Project Plan}
Chapter for Background Interim Report only, for second marker feedback




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Approach, 
Experimental Setup and Method}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Experimental Results and Discussion}
The results are very interesting in Jones 2019.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Conclusion}


%% bibliography
\bibliographystyle{unsrt}
\bibliography{References}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter*{Declarations}




\end{document}